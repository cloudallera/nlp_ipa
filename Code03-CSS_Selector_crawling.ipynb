{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CSS-Selector\" data-toc-modified-id=\"CSS-Selector-1\">CSS Selector</a></span></li><li><span><a href=\"#CSS-Selector로-포탈-검색결과에서-제목-추출하기\" data-toc-modified-id=\"CSS-Selector로-포탈-검색결과에서-제목-추출하기-2\">CSS Selector로 포탈 검색결과에서 제목 추출하기</a></span></li><li><span><a href=\"#Crawling\" data-toc-modified-id=\"Crawling-3\">Crawling</a></span></li><li><span><a href=\"#webscraping.com-사이트에서-Crawling-실습\" data-toc-modified-id=\"webscraping.com-사이트에서-Crawling-실습-4\">webscraping.com 사이트에서 Crawling 실습</a></span><ul class=\"toc-item\"><li><span><a href=\"#getUrls()-함수-만들기\" data-toc-modified-id=\"getUrls()-함수-만들기-4.1\">getUrls() 함수 만들기</a></span></li></ul></li><li><span><a href=\"#google-검색결과로-부터-External-Site-Crawling\" data-toc-modified-id=\"google-검색결과로-부터-External-Site-Crawling-5\">google 검색결과로 부터 External Site Crawling</a></span><ul class=\"toc-item\"><li><span><a href=\"#getUrls()-함수-재정의(1)\" data-toc-modified-id=\"getUrls()-함수-재정의(1)-5.1\">getUrls() 함수 재정의(1)</a></span></li><li><span><a href=\"#getUrls()-함수-재정의(2)\" data-toc-modified-id=\"getUrls()-함수-재정의(2)-5.2\">getUrls() 함수 재정의(2)</a></span></li><li><span><a href=\"#crawling-함수-테스트\" data-toc-modified-id=\"crawling-함수-테스트-5.3\">crawling 함수 테스트</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간에 keyboard 인터럽트를 하거나, 출력 결과가 너무 큰 셀들은 코멘트 처리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.download import getDownload\n",
    "from functions.search import getPortalSearchUrl\n",
    "from functions.search import getPortalToDOM\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doms = getPortalToDOM(\"파이썬 자습서\")    # (doms[0] == google, doms[1] == naver, doms[2] == daum, doms[3] == nate)\n",
    "google, naver, daum, nate = getPortalToDOM(\"파이썬 자습서\")   # 4대 포탈에서 지정 문자열을 검색 후 DOM 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "portalUrls = getPortalSearchUrl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleUrl = portalUrls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selector : Tag, ID(#아이디), Class(.class)   --> dom.select()\n",
    "- name, ^name, name$ 등 이름의 일부로 검색 가능\n",
    "- div p => find_all(div 찾고, 자손 중에 p 찾기)\n",
    "- div > p => find_all(recursive=False), div 찾고, 바로 아래 자손 중에 p 찾기\n",
    "- div + p => find(div).find_next_sibling(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selector로 포탈 검색결과에서 제목 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 자습서 — Python 3.7.2 documentation https://docs.python.org/ko/3/tutorial/index.html\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서 - 위키책 https://ko.wikibooks.org/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "byte of python(한국어판 PDF) - SourceForge http://byteofpython-korean.sourceforge.net/byte_of_python.pdf\n",
      "파이썬 강좌 및 유용한 사이트 모음 : 네이버 블로그 http://blog.naver.com/koromoon/220578871433\n",
      "Visual Studio 자습서 1단계의 Python 프로젝트 만들기 | Microsoft Docs https://docs.microsoft.com/ko-kr/visualstudio/python/tutorial-working-with-python-in-visual-studio-step-01-create-project\n",
      "Python | 자습서, API, SDK, 설명서 | AWS 개발자 센터 - Amazon.com https://aws.amazon.com/ko/developer/language/python/\n",
      "5.2 파이썬(Python) 시작하기 – Computational Thinking http://www.kucomputationalthink.org/index.php/chapter-5/5-2-getting-started-with-python/\n",
      "무료 파이썬 자습서, eBook 및 전자책 - Blue Breeze https://bluebreeze.co.kr/833\n"
     ]
    }
   ],
   "source": [
    "# 구글\n",
    "for tag in google.select(\".r > a > h3\"):\n",
    "    print(tag.text, tag.find_parent()[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 자습서 https://blog.naver.com/jhhamm?Redirect=Log&logNo=221415897996\n",
      "[python][ebook] 귀도의 파이썬 자습서(2.5) (한글 EBook) https://blog.naver.com/dev4unet?Redirect=Log&logNo=120193065174\n",
      "자료 - 파이썬 자습서 http://blog.daum.net/skcs4/2382\n",
      "[파이선] 파이썬 자습서 (한글화가 잘 되어 있네요) http://cafe.naver.com/cortexsh/1653\n",
      "파이썬 ve C언어 http://cafe.naver.com/cafec/378766\n",
      "과학 전공도서/자습서/교양서적 등 팝니다~ http://cafe.naver.com/joonggonara/545280936\n",
      "[nRF Mesh] Sending mesh packets [2-serial examples] http://cafe.naver.com/cortexsh/1694\n",
      "C언어를 배우기 전에 파이썬공부를 왜 하는가 http://cafe.naver.com/thdskarl/10317\n",
      "파이썬, 주류 언어로 부상··· 티오베와 PyPL 지표에서 상위권 http://www.ciokorea.com/news/114426\n",
      "떠오르는 심층 신경망 API, \"케라스\" 알아보기 http://www.itworld.co.kr/news/116583\n",
      "IT전문가를 위한 라즈베리 파이 프로젝트 13선 http://www.ciokorea.com/news/113478\n",
      "개발자 출신 빅토리아시크릿 모델 ... '뇌섹녀' 인증 http://www.fnnews.com/news/201809111029096827\n",
      "기술력 향상을 도울 온라인 무료 교육 사이트 8선 http://www.ciokorea.com/news/38589\n",
      "올해 대학 합격하고 컴퓨터 공학과에 https://kin.naver.com/qna/detail.nhn?d1id=11&dirId=1113&docId=320102309&qb=7YyM7J207I2sIOyekOyKteyEnA==&enc=utf8&section=kin&rank=1&search_sort=0&spq=0\n",
      "경북대학교 소프트웨어학과 진학에 관해서 https://kin.naver.com/qna/detail.nhn?d1id=1&dirId=10405&docId=297058448&qb=7YyM7J207I2sIOyekOyKteyEnA==&enc=utf8&section=kin&rank=2&search_sort=0&spq=0\n",
      "고1 공부법 및 진로 https://kin.naver.com/qna/detail.nhn?d1id=11&dirId=1104&docId=297769561&qb=7YyM7J207I2sIOyekOyKteyEnA==&enc=utf8&section=kin&rank=3&search_sort=0&spq=0\n",
      "The Python Tutorial — Python 3.7.2 documentation https://docs.python.org/3/tutorial/index.html\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서 https://ko.wikibooks.org/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서/재귀 https://ko.wikibooks.org/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C/%EC%9E%AC%EA%B7%80\n"
     ]
    }
   ],
   "source": [
    "# 네이버\n",
    "for tag in naver.select(\".type01 dt\"):\n",
    "    print(tag.a.text, tag.a[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[파이썬기초] 자습서 http://jinbonews.tistory.com/8\n",
      "무료 파이썬 자습서, eBook 및 전자책 http://bluebreeze.co.kr/833\n",
      "[python][ebook] 귀도의 파이썬 자습서(2.5) (한글 EBook) http://blog.naver.com/PostView.nhn?blogId=dev4unet&logNo=120193065174\n",
      "python자습서_ 숫자, 문자열 http://make-it-developer.tistory.com/21\n",
      "파이썬 자습서 ¶ https://docs.python.org/ko/3.7/tutorial/index.html\n",
      "【免費教育APP】파이썬 자습서|線上玩APP不花錢 http://searchapp.soft4fun.net/article/information/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C/4122219\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서/서문 http://ko.m.wikibooks.nym.mx/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C/%EC%84%9C%EB%AC%B8\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서/FAQ http://ko.m.wikibooks.nom.rs/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C/FAQ\n",
      "떠오르는 심층 신경망 API, \"케라스\" 알아보기 https://cp.news.search.daum.net/p/76899725\n",
      "파이썬, 주류 언어로 부상··· 티오베와 PyPL 지표에서 상위권 https://cp.news.search.daum.net/p/76900731\n",
      "IT전문가를 위한 라즈베리 파이 프로젝트 13선 https://cp.news.search.daum.net/p/76901247\n",
      "개발자 출신 빅토리아시크릿 모델 .. '뇌섹녀' 인증 http://v.media.daum.net/v/20180911103410467?f=o\n",
      "파이썬 정리 5일차 http://cafe.daum.net/g2G/mHOy/22?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "어떻게 무료로 데이터 과학자가 될 수 있는지((주... http://cafe.daum.net/statsas/OE8F/20?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "Genymtn http://cafe.daum.net/synstar/GDuw/3917?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "ㅁㅁㅁ http://cafe.daum.net/flowlife/S0Qo/1?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n"
     ]
    }
   ],
   "source": [
    "# 다음\n",
    "for tag in daum.select(\".mg_tit > a\"):\n",
    "    print(tag.text.strip(), tag[\"href\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[파이썬기초] 자습서 http://jinbonews.tistory.com/8\n",
      "무료 파이썬 자습서, eBook 및 전자책 http://bluebreeze.co.kr/833\n",
      "[python][ebook] 귀도의 파이썬 자습서(2.5) (한글 EBook) http://blog.naver.com/PostView.nhn?blogId=dev4unet&logNo=120193065174\n",
      "python자습서_ 숫자, 문자열 http://make-it-developer.tistory.com/21\n"
     ]
    }
   ],
   "source": [
    "# 네이트\n",
    "for tag in nate.select(\"div#blogColl .f_link_b\"):\n",
    "    print(tag.text, tag[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<a> 태그에 있는 하이퍼링크를 이용해 웹을 인덱싱 하는 작업을 Crawling 이라 합니다.`\n",
    "\n",
    "이런 작업을 반복적으로 자동으로 수행하는 Agent를 Bot이라고 합니다.\n",
    "\n",
    "`Scrapy`는 Agent를 만들어주는 Framework이고, `BeautifulSoup`은 HTML을 Parsing하는 패키지 입니다.<br>\n",
    "실습에서는 `BeautifulSoup`을 사용 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## webscraping.com 사이트에서 Crawling 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example.webscraping.com/places/default/index 사이트에서 실습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"http://example.webscraping.com/places/default/index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = getDownload(seed)\n",
    "dom = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(dom.select(\"a\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://example.webscraping.com/search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from urllib.parse import urljoin\n",
    "from requests.compat import urljoin\n",
    "\n",
    "urljoin(seed, \"/search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: #\n",
      "http://example.webscraping.com/places/default/user/register?_next=/places/default/index\n",
      "http://example.webscraping.com/places/default/user/login?_next=/places/default/index\n",
      "http://example.webscraping.com/places/default/index\n",
      "http://example.webscraping.com/places/default/search\n",
      "http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "http://example.webscraping.com/places/default/view/Albania-3\n",
      "http://example.webscraping.com/places/default/view/Algeria-4\n",
      "http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "http://example.webscraping.com/places/default/view/Andorra-6\n",
      "http://example.webscraping.com/places/default/view/Angola-7\n",
      "http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "http://example.webscraping.com/places/default/index/1\n"
     ]
    }
   ],
   "source": [
    "for tag in dom.select(\"a\"):\n",
    "    if tag.has_attr(\"href\"):\n",
    "        href = tag[\"href\"]\n",
    "        # print(href)\n",
    "        \n",
    "        # URL Normalization\n",
    "        if href.startswith(\"http\"):    # HTTP(S)\n",
    "            print(\"External : {0}\".format(href))\n",
    "        elif href.startswith(\"/\"):\n",
    "            print(urljoin(seed, href))     # internal link 인 경우 서버 주소를 추가해준다.\n",
    "        else:\n",
    "            print(\"Skipped: {0}\".format(href))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = []\n",
    "\n",
    "for tag in dom.select(\"a\"):\n",
    "    if tag.has_attr(\"href\"):\n",
    "        href = tag[\"href\"]\n",
    "        \n",
    "        # URL Normalization\n",
    "        if href.startswith(\"http\"):    # HTTP(S)\n",
    "            print(\"External : {0}\".format(href))\n",
    "        elif href.startswith(\"/\"):\n",
    "            newSeed = urljoin(seed, href)\n",
    "            if newSeed not in unseen:\n",
    "                unseen.append(newSeed)\n",
    "        else:\n",
    "            # print(\"Skipped: {0}\".format(href))\n",
    "            pass\n",
    "        \n",
    "    # print(unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getUrls() 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrls(base):\n",
    "    html = getDownload(base)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "    unseen = []\n",
    "\n",
    "    for tag in dom.select(\"a\"):\n",
    "        if tag.has_attr(\"href\"):\n",
    "            href = tag[\"href\"]\n",
    "\n",
    "            # URL Normalization\n",
    "            if href.startswith(\"http\"):    # HTTP(S)\n",
    "                # print(\"External : {0}\".format(href))\n",
    "                pass\n",
    "            elif href.startswith(\"/\"):\n",
    "                newSeed = urljoin(seed, href)\n",
    "                if newSeed not in unseen:\n",
    "                    unseen.append(newSeed)\n",
    "            else:\n",
    "                # print(\"Skipped: {0}\".format(href))\n",
    "                pass\n",
    "                \n",
    "    print(\"{0} --> {1}\".format(base, len(unseen)))\n",
    "    \n",
    "    return unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.webscraping.com/places/default/index --> 15\n"
     ]
    }
   ],
   "source": [
    "queue = getUrls(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import random\n",
    "\n",
    "# while queue:\n",
    "#     seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     time.sleep(random.randint(1, 5))\n",
    "#     unseen = getUrls(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queue = getUrls(seed)\n",
    "\n",
    "# while queue:\n",
    "#     seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     time.sleep(random.randint(1, 5))\n",
    "#     unseen = getUrls(seed)\n",
    "    \n",
    "#     print(\"Q:{0}, Unseen:{1}\".format(len(queue), len(unseen)))\n",
    "#     queue.extend(unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, [3]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "b = [3]\n",
    "a.append(b)    # list 자체가 추가됨\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "b = [3]\n",
    "a.extend(b)    # list 원소를 하나 씩 추출해서 추가함\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queue = getUrls(seed)\n",
    "# seen = []\n",
    "\n",
    "# while queue:\n",
    "#     seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     seen.append(seed)\n",
    "#     time.sleep(random.randint(1, 5))\n",
    "#     unseen = getUrls(seed)\n",
    "    \n",
    "#     print(\"Q:{0}, Unseen:{1}\".format(len(queue), len(unseen)))\n",
    "\n",
    "#     queue.extend([link for link in unseen if link not in seen and queue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## google 검색결과로 부터 External Site Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getUrls() 함수 재정의(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrls(base):\n",
    "    html = getDownload(base)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "    unseen = []\n",
    "\n",
    "    for tag in dom.select(\"a\"):\n",
    "        if tag.has_attr(\"href\"):\n",
    "            href = tag[\"href\"]\n",
    "\n",
    "            # URL Normalization\n",
    "            if href.startswith(\"http\"):    # HTTP(S)\n",
    "                if href not in unseen:\n",
    "                    unseen.append(href)\n",
    "\n",
    "            elif href.startswith(\"/\"):\n",
    "                newSeed = urljoin(seed, href)\n",
    "                if newSeed not in unseen:\n",
    "                    unseen.append(newSeed)\n",
    "                    \n",
    "            else:\n",
    "                # print(\"Skipped: {0}\".format(href))\n",
    "                pass\n",
    "                \n",
    "    print(\"{0} --> {1}\".format(base, len(unseen)))\n",
    "    \n",
    "    return unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "portalUrl = getPortalSearchUrl()\n",
    "googleUrl = portalUrl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Python.org https://www.python.org/\n",
      "파이썬 자습서 — Python 3.7.2 documentation https://docs.python.org/ko/3/tutorial/index.html\n",
      "Python - 나무위키 https://namu.wiki/w/Python\n",
      "파이썬 - 위키백과, 우리 모두의 백과사전 https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC\n",
      "파이썬 입문 | 프로그래머스 https://programmers.co.kr/learn/courses/2\n",
      "1. 파이썬 시작하기 - 왕초보를 위한 Python 2.7 - WikiDocs https://wikidocs.net/43\n",
      "01-5 파이썬 둘러보기 - 점프 투 파이썬 - WikiDocs https://wikidocs.net/9\n",
      "01-2 파이썬의 특징 - 점프 투 파이썬 - WikiDocs https://wikidocs.net/6\n",
      "02-2 문자열 자료형 - 점프 투 파이썬 - WikiDocs https://wikidocs.net/13\n",
      "Python & Ruby - 생활코딩 https://opentutorials.org/course/1750\n"
     ]
    }
   ],
   "source": [
    "html = getDownload(googleUrl, {\"q\": \"파이썬\"})\n",
    "dom = BeautifulSoup(html.text, \"lxml\")\n",
    "\n",
    "queue = []\n",
    "\n",
    "for tag in dom.select(\".r > a > h3\"):\n",
    "    href = tag.find_parent()[\"href\"]\n",
    "    print(tag.text, href)\n",
    "    queue.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " ['https://www.python.org/',\n",
       "  'https://docs.python.org/ko/3/tutorial/index.html',\n",
       "  'https://namu.wiki/w/Python',\n",
       "  'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC',\n",
       "  'https://programmers.co.kr/learn/courses/2',\n",
       "  'https://wikidocs.net/43',\n",
       "  'https://wikidocs.net/9',\n",
       "  'https://wikidocs.net/6',\n",
       "  'https://wikidocs.net/13',\n",
       "  'https://opentutorials.org/course/1750'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queue), queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for link in queue:\n",
    "#     html = getDownload(link)\n",
    "#     dom = BeautifulSoup(html.text, \"lxml\")\n",
    "#     for a in dom.select(\"a\"):\n",
    "#         if a.has_attr(\"href\"):\n",
    "#             if a[\"href\"].startswith(\"http\"):\n",
    "#                 print(a[\"href\"])\n",
    "#             elif a[\"href\"].startswith(\"/\") and len(a[\"href\"]) > 1:\n",
    "#                 print(urljoin(link, a[\"href\"]))\n",
    "#             else:\n",
    "#                 print(\"Skipped: {0}\".format(a[\"href\"]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/ --> 190\n",
      "https://docs.python.org/ko/3/tutorial/index.html --> 6\n",
      "https://namu.wiki/w/Python --> 417\n",
      "https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC --> 499\n",
      "https://programmers.co.kr/learn/courses/2 --> 161\n",
      "https://wikidocs.net/43 --> 4\n",
      "https://wikidocs.net/9 --> 6\n",
      "https://wikidocs.net/6 --> 7\n",
      "https://wikidocs.net/13 --> 8\n",
      "https://opentutorials.org/course/1750 --> 144\n"
     ]
    }
   ],
   "source": [
    "for link in queue:\n",
    "    links = []\n",
    "    html = getDownload(link)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    for a in dom.select(\"a\"):\n",
    "        if a.has_attr(\"href\"):\n",
    "            if a[\"href\"].startswith(\"http\"):\n",
    "                links.append(a[\"href\"])\n",
    "            elif a[\"href\"].startswith(\"/\") and len(a[\"href\"]) > 1:\n",
    "                links.append(urljoin(link, a[\"href\"]))\n",
    "            else:\n",
    "                pass\n",
    "                # print(\"Skipped: {0}\".format(a[\"href\"]))\n",
    "    print(\"{0} --> {1}\".format(link, len(links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getUrls() 함수 재정의(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getUrls(link, depth=3):\n",
    "    if depth > 3:\n",
    "        return None\n",
    "    \n",
    "    links = []\n",
    "    html = getDownload(link)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "\n",
    "    for a in dom.select(\"a\"):\n",
    "        if a.has_attr(\"href\"):\n",
    "            if a[\"href\"].startswith(\"http\"):\n",
    "                links.append({\"url\": a[\"href\"], \"depth\": depth+1})\n",
    "            elif a[\"href\"].startswith(\"/\") and len(a[\"href\"]) > 1:\n",
    "                links.append({\"url\": urljoin(link, a[\"href\"]), \"depth\": depth+1})\n",
    "            else:\n",
    "                pass\n",
    "                # print(\"Skipped: {0}\".format(a[\"href\"]))\n",
    "    print(\"{0} {1} -> {2}\".format(\">\" * (depth+1), link, len(links)))\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = getDownload(googleUrl, {\"q\": \"파이썬\"})\n",
    "dom = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = []\n",
    "\n",
    "for tag in dom.select(\".r > a > h3\"):\n",
    "    href = tag.find_parent()[\"href\"]\n",
    "    queue.append({\"url\": href, \"depth\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.python.org/', 'depth': 0},\n",
       " {'url': 'https://docs.python.org/ko/3/tutorial/index.html', 'depth': 0},\n",
       " {'url': 'https://namu.wiki/w/Python', 'depth': 0},\n",
       " {'url': 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC',\n",
       "  'depth': 0},\n",
       " {'url': 'https://programmers.co.kr/learn/courses/2', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/43', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/9', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/6', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/13', 'depth': 0},\n",
       " {'url': 'https://opentutorials.org/course/1750', 'depth': 0}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while queue:\n",
    "#     link = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     links = getUrls(link[\"url\"], link[\"depth\"])\n",
    "    \n",
    "#     if links != None:\n",
    "#         for newlink in links:\n",
    "#             if newlink not in queue:\n",
    "#                 queue.append({\"url\": newlink[\"url\"], \"depth\": newlink[\"depth\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crawling 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import crawling\n",
    "from functions.crawling import getUrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = getDownload(googleUrl, {\"q\": \"파이썬\"})\n",
    "dom = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = []\n",
    "\n",
    "for tag in dom.select(\".r > a > h3\"):\n",
    "    href = tag.find_parent()[\"href\"]\n",
    "    queue.append({\"url\": href, \"depth\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.python.org/', 'depth': 0},\n",
       " {'url': 'https://docs.python.org/ko/3/tutorial/index.html', 'depth': 0},\n",
       " {'url': 'https://namu.wiki/w/Python', 'depth': 0},\n",
       " {'url': 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC',\n",
       "  'depth': 0},\n",
       " {'url': 'https://programmers.co.kr/learn/courses/2', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/43', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/9', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/6', 'depth': 0},\n",
       " {'url': 'https://wikidocs.net/13', 'depth': 0},\n",
       " {'url': 'https://opentutorials.org/course/1750', 'depth': 0}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> https://www.python.org/ --> 192개 사이트 추가\n",
      "Queue:9, Unseen:192\n",
      "> https://docs.python.org/ko/3/tutorial/index.html --> 6개 사이트 추가\n",
      "Queue:200, Unseen:6\n",
      "> https://namu.wiki/w/Python --> 417개 사이트 추가\n",
      "Queue:205, Unseen:417\n",
      "> https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC --> 499개 사이트 추가\n",
      "Queue:621, Unseen:499\n",
      "> https://programmers.co.kr/learn/courses/2 --> 162개 사이트 추가\n",
      "Queue:1119, Unseen:162\n",
      "> https://wikidocs.net/43 --> 6개 사이트 추가\n",
      "Queue:1280, Unseen:6\n",
      "> https://wikidocs.net/9 --> 8개 사이트 추가\n",
      "Queue:1285, Unseen:8\n",
      "> https://wikidocs.net/6 --> 9개 사이트 추가\n",
      "Queue:1292, Unseen:9\n",
      "> https://wikidocs.net/13 --> 10개 사이트 추가\n",
      "Queue:1300, Unseen:10\n",
      "> https://opentutorials.org/course/1750 --> 144개 사이트 추가\n",
      "Queue:1309, Unseen:144\n",
      ">> https://www.python.org/ --> 192개 사이트 추가\n",
      "Queue:1452, Unseen:192\n",
      ">> https://www.python.org/psf-landing/ --> 132개 사이트 추가\n",
      "Queue:1643, Unseen:132\n",
      ">> https://docs.python.org --> 14개 사이트 추가\n",
      "Queue:1774, Unseen:14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-87a4eec7482e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#time.sleep(random.randint(1, 3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0munseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetUrls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue:{0}, Unseen:{1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ai/NLP/nlp_ipa/functions/crawling.py\u001b[0m in \u001b[0;36mgetUrls\u001b[0;34m(link, depth)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mdom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ai/NLP/nlp_ipa/functions/download.py\u001b[0m in \u001b[0;36mgetDownload\u001b[0;34m(url, params, headers, retries)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    342\u001b[0m             or IS_SECURETRANSPORT):\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         warnings.warn(\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mcnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m         \"\"\"\n\u001b[0;32m-> 1906\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seen = []\n",
    "\n",
    "while queue:\n",
    "    seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "    seen.append(seed)\n",
    "    #time.sleep(random.randint(1, 3))\n",
    "    unseen = getUrls(seed[\"url\"], seed[\"depth\"])\n",
    "    \n",
    "    print(\"Queue:{0}, Unseen:{1}\".format(len(queue), len(unseen)))\n",
    "\n",
    "    queue.extend({\"url\": link[\"url\"], \"depth\": link[\"depth\"]} for link in unseen if link not in seen and queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
