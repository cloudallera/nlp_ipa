{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Text-Normalization\" data-toc-modified-id=\"Text-Normalization-1\">Text Normalization</a></span><ul class=\"toc-item\"><li><span><a href=\"#불필요한-구두점-지우기\" data-toc-modified-id=\"불필요한-구두점-지우기-1.1\">불필요한 구두점 지우기</a></span></li><li><span><a href=\"#stopwords\" data-toc-modified-id=\"stopwords-1.2\">stopwords</a></span></li><li><span><a href=\"#한글에-불용어,-stropwords-적용\" data-toc-modified-id=\"한글에-불용어,-stropwords-적용-1.3\">한글에 불용어, stropwords 적용</a></span></li><li><span><a href=\"#불용어-사전-관련-추가-고려사항\" data-toc-modified-id=\"불용어-사전-관련-추가-고려사항-1.4\">불용어 사전 관련 추가 고려사항</a></span><ul class=\"toc-item\"><li><span><a href=\"#짧은-어휘-처리\" data-toc-modified-id=\"짧은-어휘-처리-1.4.1\">짧은 어휘 처리</a></span></li><li><span><a href=\"#빈도수-처리\" data-toc-modified-id=\"빈도수-처리-1.4.2\">빈도수 처리</a></span></li></ul></li></ul></li><li><span><a href=\"#비속어-사전\" data-toc-modified-id=\"비속어-사전-2\">비속어 사전</a></span><ul class=\"toc-item\"><li><span><a href=\"#ngramEojeol()\" data-toc-modified-id=\"ngramEojeol()-2.1\">ngramEojeol()</a></span></li><li><span><a href=\"#ngramUmjeol()\" data-toc-modified-id=\"ngramUmjeol()-2.2\">ngramUmjeol()</a></span></li><li><span><a href=\"#findNgram()\" data-toc-modified-id=\"findNgram()-2.3\">findNgram()</a></span></li><li><span><a href=\"#splitTerms()\" data-toc-modified-id=\"splitTerms()-2.4\">splitTerms()</a></span></li></ul></li><li><span><a href=\"#형태소-분석---POS-Taggers\" data-toc-modified-id=\"형태소-분석---POS-Taggers-3\">형태소 분석 - POS Taggers</a></span><ul class=\"toc-item\"><li><span><a href=\"#품사-분석기-:-nltk.pos_tag()\" data-toc-modified-id=\"품사-분석기-:-nltk.pos_tag()-3.1\">품사 분석기 : nltk.pos_tag()</a></span></li><li><span><a href=\"#Tag-Sets\" data-toc-modified-id=\"Tag-Sets-3.2\">Tag Sets</a></span></li><li><span><a href=\"#untag\" data-toc-modified-id=\"untag-3.3\">untag</a></span></li><li><span><a href=\"#FreqDist()\" data-toc-modified-id=\"FreqDist()-3.4\">FreqDist()</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Segmenting/tokenizing words\n",
    "- Normalizing word formats\n",
    "- Segmenting sentences\n",
    "\n",
    "Normalization Issue(영어)\n",
    "\n",
    "![normalizationissue](./images/normalization_issue.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 불필요한 구두점 지우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[!\"\\#\\$%\\&\\'\\(\\)\\*\\+,\\-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}\\~]',\n",
       "re.UNICODE)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I'd like to learn more somthing.\"\n",
    "pattern = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'d\", 'like', 'to', 'learn', 'more', 'somthing', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_tokenize:  ['I', \"'d\", 'like', 'to', 'learn', 'more', 'somthing', '.']\n",
      "normalization:  ['I', 'd', 'like', 'to', 'learn', 'more', 'somthing']\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "print(\"word_tokenize: \", word_tokenize(sentence))\n",
    "\n",
    "for term in word_tokenize(sentence):\n",
    "    # re.sub(pattern, \"\", term)\n",
    "    new = pattern.sub(\"\", term)\n",
    "    if new:\n",
    "        tokens.append(new)\n",
    "\n",
    "print(\"normalization: \", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_tokenize:  ['파이썬', ',', '자연어처리', ',', '그리고', '어쩌고']\n",
      "normalization:  ['파이썬', '자연어처리', '그리고', '어쩌고']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"파이썬, 자연어처리, 그리고 어쩌고\"\n",
    "pattern = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "\n",
    "tokens = []\n",
    "\n",
    "print(\"word_tokenize: \", word_tokenize(sentence))\n",
    "\n",
    "for term in word_tokenize(sentence):\n",
    "    # re.sub(pattern, \"\", term)\n",
    "    new = pattern.sub(\"\", term)\n",
    "    if new:\n",
    "        tokens.append(new)\n",
    "\n",
    "print(\"normalization: \", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i\\nme\\nmy\\nmyself\\nwe\\nour\\nours\\nourselves\\nyou\\nyou're\\nyou've\\nyou'll\\nyou'd\\nyour\\nyours\\nyourself\\nyourselves\\nhe\\nhim\\nhis\\nhimself\\nshe\\nshe's\\nher\\nhers\\nherself\\nit\\nit's\\nits\\nitself\\nthey\\nthem\\ntheir\\ntheirs\\nthemselves\\nwhat\\nwhich\\nwho\\nwhom\\nthis\\nthat\\nthat'll\\nthese\\nthose\\nam\\nis\\nare\\nwas\\nwere\\nbe\\nbeen\\nbeing\\nhave\\nhas\\nhad\\nhaving\\ndo\\ndoes\\ndid\\ndoing\\na\\nan\\nthe\\nand\\nbut\\nif\\nor\\nbecause\\nas\\nuntil\\nwhile\\nof\\nat\\nby\\nfor\\nwith\\nabout\\nagainst\\nbetween\\ninto\\nthrough\\nduring\\nbefore\\nafter\\nabove\\nbelow\\nto\\nfrom\\nup\\ndown\\nin\\nout\\non\\noff\\nover\\nunder\\nagain\\nfurther\\nthen\\nonce\\nhere\\nthere\\nwhen\\nwhere\\nwhy\\nhow\\nall\\nany\\nboth\\neach\\nfew\\nmore\\nmost\\nother\\nsome\\nsuch\\nno\\nnor\\nnot\\nonly\\nown\\nsame\\nso\\nthan\\ntoo\\nvery\\ns\\nt\\ncan\\nwill\\njust\\ndon\\ndon't\\nshould\\nshould've\\nnow\\nd\\nll\\nm\\no\\nre\\nve\\ny\\nain\\naren\\naren't\\ncouldn\\ncouldn't\\ndidn\\ndidn't\\ndoesn\\ndoesn't\\nhadn\\nhadn't\\nhasn\\nhasn't\\nhaven\\nhaven't\\nisn\\nisn't\\nma\\nmightn\\nmightn't\\nmustn\\nmustn't\\nneedn\\nneedn't\\nshan\\nshan't\\nshouldn\\nshouldn't\\nwasn\\nwasn't\\nweren\\nweren't\\nwon\\nwon't\\nwouldn\\nwouldn't\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.open(\"english\").read()\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:  ['Beautiful', 'is', 'better', 'than', 'ugly.']\n",
      "word_tokenize:  ['Beautiful', 'is', 'better', 'than', 'ugly', '.']\n",
      "clean_stopwords:  ['Beautiful', 'better', 'ugly']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Beautiful is better than ugly.\"\n",
    "print(\"split: \", sentence.split())\n",
    "print(\"word_tokenize: \", word_tokenize(sentence))\n",
    "\n",
    "pattern = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "sentence = pattern.sub(\"\", sentence)\n",
    "\n",
    "terms = word_tokenize(sentence)\n",
    "clearnTerms = []\n",
    "\n",
    "for term in terms:\n",
    "    if term not in stop:\n",
    "        clearnTerms.append(term)\n",
    "\n",
    "print(\"clean_stopwords: \", clearnTerms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 한글에 불용어, stropwords 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:  ['어머님', '은', '자장면', '이,', '싫다', '고', '하셨', '어.']\n",
      "word_tokenize:  ['어머님', '은', '자장면', '이', ',', '싫다', '고', '하셨', '어', '.']\n",
      "clean_stopwords:  ['어머님', '자장면', '싫다', '하셨', '어']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"어머님 은 자장면 이, 싫다 고 하셨 어.\"\n",
    "ko_stop = [\"은\", \"는\", \"이\", \"가\", \"고\", \"께\", \"을\", \"를\", \"께서\", \"게\", \"에게\"]   # stopwords 정의\n",
    "print(\"split: \", sentence.split())\n",
    "print(\"word_tokenize: \", word_tokenize(sentence))\n",
    "\n",
    "pattern = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "sentence = pattern.sub(\"\", sentence)\n",
    "\n",
    "terms = word_tokenize(sentence)\n",
    "clearnTerms = []\n",
    "\n",
    "for term in terms:\n",
    "    if term not in ko_stop:\n",
    "        clearnTerms.append(term)\n",
    "\n",
    "print(\"clean_stopwords: \", clearnTerms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 불용어 사전 관련 추가 고려사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- 영어의 경우 대소문자 : 소문자로 바꿔서 처리  => 한글 문장 내에도 영어가 있을 수 있음\n",
    "    - 축약어 : 대소문자의 의미가 있음 ==> 도메인에 따라 다르게 정의할 수도 있음\n",
    "- 짧은 어휘 : 너무 짧은 글자는 제거 (또는 너무 긴 단어도 제거)\n",
    "- 저빈도 어휘 : 너무 드문 단어 제거\n",
    "- 정규 표현식을 사용\n",
    "- 구어체에서는 신조어를 중요하게 생각해야 할 수도 있음(추가 해야 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **한글 불용어와 비속어**\n",
    "\n",
    "![불용어](./images/한글-불용어_비속어.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 짧은 어휘 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd\n",
      "like\n",
      "learn\n",
      "more\n",
      "somthing.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I'd like to learn more somthing.\"\n",
    "\n",
    "threshold = 2 \n",
    "\n",
    "for token in sentence.split():\n",
    "    if len(token) > threshold:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n",
      "learn\n",
      "more\n",
      "somthing\n"
     ]
    }
   ],
   "source": [
    "for token in word_tokenize(sentence):\n",
    "    if len(token) > threshold:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to learn more somthing.\n",
      " '  like   learn more somthing.\n"
     ]
    }
   ],
   "source": [
    "# 정규식 표현\n",
    "# \\W\\b.+\\b\\W : \\W는 word가 아닌 것, \\w는 word인것, \\b는 경계(boundary)\n",
    "# {1, 2} : 1글자~2글자\n",
    "# {2, } : 2글자 이상\n",
    "# regular expression cheetsheet 참고\n",
    "\n",
    "pattern = re.compile(r\"\\b\\w{1,%d}\\b\" % threshold)\n",
    "print(sentence)\n",
    "print(pattern.sub(\" \", sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 빈도수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped : I => 3\n",
      ">> 'd\n",
      ">> like\n",
      ">> to\n",
      ">> learn\n",
      ">> more\n",
      "Skipped : somthing => 1\n",
      ">> .\n"
     ]
    }
   ],
   "source": [
    "from nltk import Text\n",
    "\n",
    "sentence = \"I'd like to learn more somthing. I'd like to learn more I.\"\n",
    "\n",
    "tokens = Text(word_tokenize(sentence))\n",
    "for k in tokens.vocab():\n",
    "    if tokens.count(k) > 2 or tokens.count(k) < 2:\n",
    "        print(\"Skipped : {0} => {1}\".format(k, tokens.count(k)))\n",
    "    else:\n",
    "        print(\">>\", k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 비속어 사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** 짜증나 씨발짜증나'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = [\"시발\", \"씨발\"]\n",
    "sentence = \"시발 짜증나 씨발짜증나\"\n",
    "result = []\n",
    "\n",
    "for term in sentence.split():\n",
    "    if term in stop:\n",
    "        result.append(\"*\" * len(term))\n",
    "    else:\n",
    "        result.append(term)\n",
    "\n",
    "\" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ngramEojeol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['동해물과 백두산이', '백두산이 마르고', '마르고 닳도록']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어절 단위의 ngram (n=2)\n",
    "def ngramEojeol(sentence, n=2):\n",
    "    '''\n",
    "    입력: 단어1, 단어2, 단어3, 단어4 : 4\n",
    "    출력(2) : 단어12, 단어23, 단어34 : 3 - n + 1\n",
    "    출력(3) : 단어123, 단어234         : 2 - n + 1\n",
    "    '''\n",
    "    tokens = sentence.split()\n",
    "    ngram = []\n",
    "    \n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram.append(\" \".join(tokens[i:i+n]))    # 공백을 추가해줘야 단어 사이가 구분됨\n",
    "        \n",
    "    return ngram\n",
    "\n",
    "ngramEojeol(\"동해물과 백두산이 마르고 닳도록\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ngramUmjeol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['국민', '민의', '의국', '국민', '민을', '을국', '국민', '민에']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음절 단위의 ngram (n=2)\n",
    "def ngramUmjeol(term, n=2):\n",
    "    '''\n",
    "    입력: 음절1, 음절2, 음절3, 음절4 : 4\n",
    "    출력(2) : 음절12, 음절23, 음절34 : 3 - n + 1\n",
    "    출력(3) : 음절123, 음절234         : 2 - n + 1\n",
    "    '''\n",
    "    ngram = []\n",
    "    \n",
    "    for i in range(len(term) - n + 1):\n",
    "        ngram.append(\"\".join(term[i:i+n]))    # 공백 없이 붙여서 단어를 만듦\n",
    "        \n",
    "    return ngram\n",
    "\n",
    "ngramUmjeol(\"국민의국민을국민에\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "split 만으로는 음절을 정확히 처리하지 못했음(띄어쓰기 안하는 경우...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** 짜증나 ***** **'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = [\"시발\", \"씨발\"]\n",
    "sentence = \"시발 짜증나 씨발짜증나 씨발\"\n",
    "result = []\n",
    "\n",
    "for term in sentence.split():\n",
    "    if term in stop:\n",
    "        result.append(\"*\" * len(term))\n",
    "    else:\n",
    "        flag = False\n",
    "        for token in ngramUmjeol(term):\n",
    "            if token in stop:\n",
    "                flag = True\n",
    "        \n",
    "        if flag == True:\n",
    "            result.append(\"*\" * len(term))\n",
    "        else:\n",
    "            result.append(term)\n",
    "\n",
    "\" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stopword 중간에 문자가 포함된 경우는 걸러내지 못함\n",
    "stop = [\"시발\", \"씨발\"]\n",
    "sentence = \"시~발 짜증나 씨발짜증나 씨1발\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시~발 짜증나 씨발짜증나 씨1발\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r\"\\B\\[0-9]+\\B\")\n",
    "sentence = pattern.sub(\"\", sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** 짜증나 ***** ** 시~발 짜증나 ***** 씨1발'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for term in sentence.split():\n",
    "    if term in stop:\n",
    "        result.append(\"*\" * len(term))\n",
    "    else:\n",
    "        flag = False\n",
    "        for token in ngramUmjeol(term):\n",
    "            if token in stop:\n",
    "                flag = True\n",
    "        \n",
    "        if flag:\n",
    "            result.append(\"*\" * len(term))\n",
    "        else:\n",
    "            result.append(term)\n",
    "\n",
    "\" \".join(result)\n",
    "\n",
    "# ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### findNgram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def findNgram(tokens, n=2):\n",
    "    result = defaultdict(int)    # {}  : dictionary 객체 생성\n",
    "    \n",
    "    for k, v in tokens.items():\n",
    "        term = k.split()\n",
    "        \n",
    "        for i in range(len(term) - n + 1):\n",
    "            ngram = (term[i], term[i+1])\n",
    "            # (l, o), (o, w), (w, </w>)\n",
    "            \n",
    "            if ngram in result.keys():\n",
    "                result[ngram] += v\n",
    "            else:\n",
    "                result[ngram] = v\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### splitTerms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l o w e r </w> _ l o w e s t </w>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def splitTerms(term):\n",
    "    # t = term.replace(\" \", \"_\")  # 공백 치환\n",
    "    termLists = term.split()\n",
    "    result = []\n",
    "\n",
    "    for termList in termLists:\n",
    "        result.append(\" \".join(list(termList)+['</w>']))\n",
    "    return \" _ \".join(result)\n",
    "\n",
    "splitTerms(\"lower lowest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    splitTerms(\"시발\"):10,\n",
    "    splitTerms(\"시1발\"):2,\n",
    "    splitTerms(\"시!발\"):2,\n",
    "    splitTerms(\"시123발\"):2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('시', '발'): 10,\n",
       "             ('발', '</w>'): 16,\n",
       "             ('시', '1'): 4,\n",
       "             ('1', '발'): 2,\n",
       "             ('시', '!'): 2,\n",
       "             ('!', '발'): 2,\n",
       "             ('1', '2'): 2,\n",
       "             ('2', '3'): 2,\n",
       "             ('3', '발'): 2})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findNgram(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** ******** ****'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    pattern = findNgram(data)\n",
    "    maxKey = max(pattern, key=pattern.get)\n",
    "\n",
    "pattern = findNgram(data)\n",
    "maxKey = max(pattern, key=pattern.get)\n",
    "\n",
    "sentence = \"시발 시112312발 시!a발\"\n",
    "repattern = re.compile(maxKey[0] + \".*\"  + maxKey[1])\n",
    "\n",
    "result = []\n",
    "for token in sentence.split():\n",
    "    if repattern.search(\"<w>{0}</w>\".format(token)):\n",
    "        result.append(\"*\" * len(token))\n",
    "    else:\n",
    "        result.append(token)\n",
    "\n",
    "\" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 형태소 분석 - POS Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"She sells seashells on the seashore.\"\n",
    "\n",
    "![POS_Tagging](./images/POS_Tagging.png)\n",
    "\n",
    "- 많은 형태소 분석기, 품사 Taggers 중에 적합한 것을 선택해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"She sells seashells on the seashore.\"\n",
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She', 'sells', 'seashells', 'on', 'the', 'seashore', '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 품사 분석기 : nltk.pos_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alex/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag   # 형태소 분석기(품사 분석기) : tag set을 내장하고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRP'),\n",
       " ('sells', 'VBZ'),\n",
       " ('seashells', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('seashore', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She sells seashells on the seashore'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "pattern.sub(\"\", sentence)   # 구두점 제거됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escape: .\n",
      "['she', 'sells', 'seashells', 'on', 'the', 'seashore']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for token in tokens:\n",
    "    if pattern.search(token):\n",
    "        print(\"escape:\", token)\n",
    "    else:\n",
    "        result.append(token.lower())\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she', 'PRP'),\n",
       " ('sells', 'VBZ'),\n",
       " ('seashells', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('seashore', 'NN')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/alex/nltk_data...\n",
      "[nltk_data]   Unzipping help/tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.help import brown_tagset, upenn_tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(: opening parenthesis\n",
      "    (\n",
      "): closing parenthesis\n",
      "    )\n",
      "*: negator\n",
      "    not n't\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ? ; ! :\n",
      ":: colon\n",
      "    :\n",
      "ABL: determiner/pronoun, pre-qualifier\n",
      "    quite such rather\n",
      "ABN: determiner/pronoun, pre-quantifier\n",
      "    all half many nary\n",
      "ABX: determiner/pronoun, double conjunction or pre-quantifier\n",
      "    both\n",
      "AP: determiner/pronoun, post-determiner\n",
      "    many other next more last former little several enough most least only\n",
      "    very few fewer past same Last latter less single plenty 'nough lesser\n",
      "    certain various manye next-to-last particular final previous present\n",
      "    nuf\n",
      "AP$: determiner/pronoun, post-determiner, genitive\n",
      "    other's\n",
      "AP+AP: determiner/pronoun, post-determiner, hyphenated pair\n",
      "    many-much\n",
      "AT: article\n",
      "    the an no a every th' ever' ye\n",
      "BE: verb 'to be', infinitive or imperative\n",
      "    be\n",
      "BED: verb 'to be', past tense, 2nd person singular or all persons plural\n",
      "    were\n",
      "BED*: verb 'to be', past tense, 2nd person singular or all persons plural, negated\n",
      "    weren't\n",
      "BEDZ: verb 'to be', past tense, 1st and 3rd person singular\n",
      "    was\n",
      "BEDZ*: verb 'to be', past tense, 1st and 3rd person singular, negated\n",
      "    wasn't\n",
      "BEG: verb 'to be', present participle or gerund\n",
      "    being\n",
      "BEM: verb 'to be', present tense, 1st person singular\n",
      "    am\n",
      "BEM*: verb 'to be', present tense, 1st person singular, negated\n",
      "    ain't\n",
      "BEN: verb 'to be', past participle\n",
      "    been\n",
      "BER: verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    are art\n",
      "BER*: verb 'to be', present tense, 2nd person singular or all persons plural, negated\n",
      "    aren't ain't\n",
      "BEZ: verb 'to be', present tense, 3rd person singular\n",
      "    is\n",
      "BEZ*: verb 'to be', present tense, 3rd person singular, negated\n",
      "    isn't ain't\n",
      "CC: conjunction, coordinating\n",
      "    and or but plus & either neither nor yet 'n' and/or minus an'\n",
      "CD: numeral, cardinal\n",
      "    two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5\n",
      "    seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six\n",
      "    ...\n",
      "CD$: numeral, cardinal, genitive\n",
      "    1960's 1961's .404's\n",
      "CS: conjunction, subordinating\n",
      "    that as after whether before while like because if since for than altho\n",
      "    until so unless though providing once lest s'posin' till whereas\n",
      "    whereupon supposing tho' albeit then so's 'fore\n",
      "DO: verb 'to do', uninflected present tense, infinitive or imperative\n",
      "    do dost\n",
      "DO*: verb 'to do', uninflected present tense or imperative, negated\n",
      "    don't\n",
      "DO+PPSS: verb 'to do', past or present tense + pronoun, personal, nominative, not 3rd person singular\n",
      "    d'you\n",
      "DOD: verb 'to do', past tense\n",
      "    did done\n",
      "DOD*: verb 'to do', past tense, negated\n",
      "    didn't\n",
      "DOZ: verb 'to do', present tense, 3rd person singular\n",
      "    does\n",
      "DOZ*: verb 'to do', present tense, 3rd person singular, negated\n",
      "    doesn't don't\n",
      "DT: determiner/pronoun, singular\n",
      "    this each another that 'nother\n",
      "DT$: determiner/pronoun, singular, genitive\n",
      "    another's\n",
      "DT+BEZ: determiner/pronoun + verb 'to be', present tense, 3rd person singular\n",
      "    that's\n",
      "DT+MD: determiner/pronoun + modal auxillary\n",
      "    that'll this'll\n",
      "DTI: determiner/pronoun, singular or plural\n",
      "    any some\n",
      "DTS: determiner/pronoun, plural\n",
      "    these those them\n",
      "DTS+BEZ: pronoun, plural + verb 'to be', present tense, 3rd person singular\n",
      "    them's\n",
      "DTX: determiner, pronoun or double conjunction\n",
      "    neither either one\n",
      "EX: existential there\n",
      "    there\n",
      "EX+BEZ: existential there + verb 'to be', present tense, 3rd person singular\n",
      "    there's\n",
      "EX+HVD: existential there + verb 'to have', past tense\n",
      "    there'd\n",
      "EX+HVZ: existential there + verb 'to have', present tense, 3rd person singular\n",
      "    there's\n",
      "EX+MD: existential there + modal auxillary\n",
      "    there'll there'd\n",
      "FW-*: foreign word: negator\n",
      "    pas non ne\n",
      "FW-AT: foreign word: article\n",
      "    la le el un die der ein keine eine das las les Il\n",
      "FW-AT+NN: foreign word: article + noun, singular, common\n",
      "    l'orchestre l'identite l'arcade l'ange l'assistance l'activite\n",
      "    L'Universite l'independance L'Union L'Unita l'osservatore\n",
      "FW-AT+NP: foreign word: article + noun, singular, proper\n",
      "    L'Astree L'Imperiale\n",
      "FW-BE: foreign word: verb 'to be', infinitive or imperative\n",
      "    sit\n",
      "FW-BER: foreign word: verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    sind sunt etes\n",
      "FW-BEZ: foreign word: verb 'to be', present tense, 3rd person singular\n",
      "    ist est\n",
      "FW-CC: foreign word: conjunction, coordinating\n",
      "    et ma mais und aber och nec y\n",
      "FW-CD: foreign word: numeral, cardinal\n",
      "    une cinq deux sieben unam zwei\n",
      "FW-CS: foreign word: conjunction, subordinating\n",
      "    bevor quam ma\n",
      "FW-DT: foreign word: determiner/pronoun, singular\n",
      "    hoc\n",
      "FW-DT+BEZ: foreign word: determiner + verb 'to be', present tense, 3rd person singular\n",
      "    c'est\n",
      "FW-DTS: foreign word: determiner/pronoun, plural\n",
      "    haec\n",
      "FW-HV: foreign word: verb 'to have', present tense, not 3rd person singular\n",
      "    habe\n",
      "FW-IN: foreign word: preposition\n",
      "    ad de en a par con dans ex von auf super post sine sur sub avec per\n",
      "    inter sans pour pendant in di\n",
      "FW-IN+AT: foreign word: preposition + article\n",
      "    della des du aux zur d'un del dell'\n",
      "FW-IN+NN: foreign word: preposition + noun, singular, common\n",
      "    d'etat d'hotel d'argent d'identite d'art\n",
      "FW-IN+NP: foreign word: preposition + noun, singular, proper\n",
      "    d'Yquem d'Eiffel\n",
      "FW-JJ: foreign word: adjective\n",
      "    avant Espagnol sinfonica Siciliana Philharmonique grand publique haute\n",
      "    noire bouffe Douce meme humaine bel serieuses royaux anticus presto\n",
      "    Sovietskaya Bayerische comique schwarzen ...\n",
      "FW-JJR: foreign word: adjective, comparative\n",
      "    fortiori\n",
      "FW-JJT: foreign word: adjective, superlative\n",
      "    optimo\n",
      "FW-NN: foreign word: noun, singular, common\n",
      "    ballet esprit ersatz mano chatte goutte sang Fledermaus oud def kolkhoz\n",
      "    roi troika canto boite blutwurst carne muzyka bonheur monde piece force\n",
      "    ...\n",
      "FW-NN$: foreign word: noun, singular, common, genitive\n",
      "    corporis intellectus arte's dei aeternitatis senioritatis curiae\n",
      "    patronne's chambre's\n",
      "FW-NNS: foreign word: noun, plural, common\n",
      "    al culpas vopos boites haflis kolkhozes augen tyrannis alpha-beta-\n",
      "    gammas metis banditos rata phis negociants crus Einsatzkommandos\n",
      "    kamikaze wohaws sabinas zorrillas palazzi engages coureurs corroborees\n",
      "    yori Ubermenschen ...\n",
      "FW-NP: foreign word: noun, singular, proper\n",
      "    Karshilama Dieu Rundfunk Afrique Espanol Afrika Spagna Gott Carthago\n",
      "    deus\n",
      "FW-NPS: foreign word: noun, plural, proper\n",
      "    Svenskarna Atlantes Dieux\n",
      "FW-NR: foreign word: noun, singular, adverbial\n",
      "    heute morgen aujourd'hui hoy\n",
      "FW-OD: foreign word: numeral, ordinal\n",
      "    18e 17e quintus\n",
      "FW-PN: foreign word: pronoun, nominal\n",
      "    hoc\n",
      "FW-PP$: foreign word: determiner, possessive\n",
      "    mea mon deras vos\n",
      "FW-PPL: foreign word: pronoun, singular, reflexive\n",
      "    se\n",
      "FW-PPL+VBZ: foreign word: pronoun, singular, reflexive + verb, present tense, 3rd person singular\n",
      "    s'excuse s'accuse\n",
      "FW-PPO: pronoun, personal, accusative\n",
      "    lui me moi mi\n",
      "FW-PPO+IN: foreign word: pronoun, personal, accusative + preposition\n",
      "    mecum tecum\n",
      "FW-PPS: foreign word: pronoun, personal, nominative, 3rd person singular\n",
      "    il\n",
      "FW-PPSS: foreign word: pronoun, personal, nominative, not 3rd person singular\n",
      "    ich vous sie je\n",
      "FW-PPSS+HV: foreign word: pronoun, personal, nominative, not 3rd person singular + verb 'to have', present tense, not 3rd person singular\n",
      "    j'ai\n",
      "FW-QL: foreign word: qualifier\n",
      "    minus\n",
      "FW-RB: foreign word: adverb\n",
      "    bas assai deja um wiederum cito velociter vielleicht simpliciter non zu\n",
      "    domi nuper sic forsan olim oui semper tout despues hors\n",
      "FW-RB+CC: foreign word: adverb + conjunction, coordinating\n",
      "    forisque\n",
      "FW-TO+VB: foreign word: infinitival to + verb, infinitive\n",
      "    d'entretenir\n",
      "FW-UH: foreign word: interjection\n",
      "    sayonara bien adieu arigato bonjour adios bueno tchalo ciao o\n",
      "FW-VB: foreign word: verb, present tense, not 3rd person singular, imperative or infinitive\n",
      "    nolo contendere vive fermate faciunt esse vade noli tangere dites duces\n",
      "    meminisse iuvabit gosaimasu voulez habla ksu'u'peli'afo lacheln miuchi\n",
      "    say allons strafe portant\n",
      "FW-VBD: foreign word: verb, past tense\n",
      "    stabat peccavi audivi\n",
      "FW-VBG: foreign word: verb, present participle or gerund\n",
      "    nolens volens appellant seq. obliterans servanda dicendi delenda\n",
      "FW-VBN: foreign word: verb, past participle\n",
      "    vue verstrichen rasa verboten engages\n",
      "FW-VBZ: foreign word: verb, present tense, 3rd person singular\n",
      "    gouverne sinkt sigue diapiace\n",
      "FW-WDT: foreign word: WH-determiner\n",
      "    quo qua quod que quok\n",
      "FW-WPO: foreign word: WH-pronoun, accusative\n",
      "    quibusdam\n",
      "FW-WPS: foreign word: WH-pronoun, nominative\n",
      "    qui\n",
      "HV: verb 'to have', uninflected present tense, infinitive or imperative\n",
      "    have hast\n",
      "HV*: verb 'to have', uninflected present tense or imperative, negated\n",
      "    haven't ain't\n",
      "HV+TO: verb 'to have', uninflected present tense + infinitival to\n",
      "    hafta\n",
      "HVD: verb 'to have', past tense\n",
      "    had\n",
      "HVD*: verb 'to have', past tense, negated\n",
      "    hadn't\n",
      "HVG: verb 'to have', present participle or gerund\n",
      "    having\n",
      "HVN: verb 'to have', past participle\n",
      "    had\n",
      "HVZ: verb 'to have', present tense, 3rd person singular\n",
      "    has hath\n",
      "HVZ*: verb 'to have', present tense, 3rd person singular, negated\n",
      "    hasn't ain't\n",
      "IN: preposition\n",
      "    of in for by considering to on among at through with under into\n",
      "    regarding than since despite according per before toward against as\n",
      "    after during including between without except upon out over ...\n",
      "IN+IN: preposition, hyphenated pair\n",
      "    f'ovuh\n",
      "IN+PPO: preposition + pronoun, personal, accusative\n",
      "    t'hi-im\n",
      "JJ: adjective\n",
      "    ecent over-all possible hard-fought favorable hard meager fit such\n",
      "    widespread outmoded inadequate ambiguous grand clerical effective\n",
      "    orderly federal foster general proportionate ...\n",
      "JJ$: adjective, genitive\n",
      "    Great's\n",
      "JJ+JJ: adjective, hyphenated pair\n",
      "    big-large long-far\n",
      "JJR: adjective, comparative\n",
      "    greater older further earlier later freer franker wider better deeper\n",
      "    firmer tougher faster higher bigger worse younger lighter nicer slower\n",
      "    happier frothier Greater newer Elder ...\n",
      "JJR+CS: adjective + conjunction, coordinating\n",
      "    lighter'n\n",
      "JJS: adjective, semantically superlative\n",
      "    top chief principal northernmost master key head main tops utmost\n",
      "    innermost foremost uppermost paramount topmost\n",
      "JJT: adjective, superlative\n",
      "    best largest coolest calmest latest greatest earliest simplest\n",
      "    strongest newest fiercest unhappiest worst youngest worthiest fastest\n",
      "    hottest fittest lowest finest smallest staunchest ...\n",
      "MD: modal auxillary\n",
      "    should may might will would must can could shall ought need wilt\n",
      "MD*: modal auxillary, negated\n",
      "    cannot couldn't wouldn't can't won't shouldn't shan't mustn't musn't\n",
      "MD+HV: modal auxillary + verb 'to have', uninflected form\n",
      "    shouldda musta coulda must've woulda could've\n",
      "MD+PPSS: modal auxillary + pronoun, personal, nominative, not 3rd person singular\n",
      "    willya\n",
      "MD+TO: modal auxillary + infinitival to\n",
      "    oughta\n",
      "NN: noun, singular, common\n",
      "    failure burden court fire appointment awarding compensation Mayor\n",
      "    interim committee fact effect airport management surveillance jail\n",
      "    doctor intern extern night weekend duty legislation Tax Office ...\n",
      "NN$: noun, singular, common, genitive\n",
      "    season's world's player's night's chapter's golf's football's\n",
      "    baseball's club's U.'s coach's bride's bridegroom's board's county's\n",
      "    firm's company's superintendent's mob's Navy's ...\n",
      "NN+BEZ: noun, singular, common + verb 'to be', present tense, 3rd person singular\n",
      "    water's camera's sky's kid's Pa's heat's throat's father's money's\n",
      "    undersecretary's granite's level's wife's fat's Knife's fire's name's\n",
      "    hell's leg's sun's roulette's cane's guy's kind's baseball's ...\n",
      "NN+HVD: noun, singular, common + verb 'to have', past tense\n",
      "    Pa'd\n",
      "NN+HVZ: noun, singular, common + verb 'to have', present tense, 3rd person singular\n",
      "    guy's Knife's boat's summer's rain's company's\n",
      "NN+IN: noun, singular, common + preposition\n",
      "    buncha\n",
      "NN+MD: noun, singular, common + modal auxillary\n",
      "    cowhand'd sun'll\n",
      "NN+NN: noun, singular, common, hyphenated pair\n",
      "    stomach-belly\n",
      "NNS: noun, plural, common\n",
      "    irregularities presentments thanks reports voters laws legislators\n",
      "    years areas adjustments chambers $100 bonds courts sales details raises\n",
      "    sessions members congressmen votes polls calls ...\n",
      "NNS$: noun, plural, common, genitive\n",
      "    taxpayers' children's members' States' women's cutters' motorists'\n",
      "    steelmakers' hours' Nations' lawyers' prisoners' architects' tourists'\n",
      "    Employers' secretaries' Rogues' ...\n",
      "NNS+MD: noun, plural, common + modal auxillary\n",
      "    duds'd oystchers'll\n",
      "NP: noun, singular, proper\n",
      "    Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n",
      "    Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n",
      "    Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n",
      "NP$: noun, singular, proper, genitive\n",
      "    Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's\n",
      "    Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's\n",
      "    Shea's Palmer's Arnold's Broglio's ...\n",
      "NP+BEZ: noun, singular, proper + verb 'to be', present tense, 3rd person singular\n",
      "    W.'s Ike's Mack's Jack's Kate's Katharine's Black's Arthur's Seaton's\n",
      "    Buckhorn's Breed's Penny's Rob's Kitty's Blackwell's Myra's Wally's\n",
      "    Lucille's Springfield's Arlene's\n",
      "NP+HVZ: noun, singular, proper + verb 'to have', present tense, 3rd person singular\n",
      "    Bill's Guardino's Celie's Skolman's Crosson's Tim's Wally's\n",
      "NP+MD: noun, singular, proper + modal auxillary\n",
      "    Gyp'll John'll\n",
      "NPS: noun, plural, proper\n",
      "    Chases Aderholds Chapelles Armisteads Lockies Carbones French Marskmen\n",
      "    Toppers Franciscans Romans Cadillacs Masons Blacks Catholics British\n",
      "    Dixiecrats Mississippians Congresses ...\n",
      "NPS$: noun, plural, proper, genitive\n",
      "    Republicans' Orioles' Birds' Yanks' Redbirds' Bucs' Yankees' Stevenses'\n",
      "    Geraghtys' Burkes' Wackers' Achaeans' Dresbachs' Russians' Democrats'\n",
      "    Gershwins' Adventists' Negroes' Catholics' ...\n",
      "NR: noun, singular, adverbial\n",
      "    Friday home Wednesday Tuesday Monday Sunday Thursday yesterday tomorrow\n",
      "    tonight West East Saturday west left east downtown north northeast\n",
      "    southeast northwest North South right ...\n",
      "NR$: noun, singular, adverbial, genitive\n",
      "    Saturday's Monday's yesterday's tonight's tomorrow's Sunday's\n",
      "    Wednesday's Friday's today's Tuesday's West's Today's South's\n",
      "NR+MD: noun, singular, adverbial + modal auxillary\n",
      "    today'll\n",
      "NRS: noun, plural, adverbial\n",
      "    Sundays Mondays Saturdays Wednesdays Souths Fridays\n",
      "OD: numeral, ordinal\n",
      "    first 13th third nineteenth 2d 61st second sixth eighth ninth twenty-\n",
      "    first eleventh 50th eighteenth- Thirty-ninth 72nd 1/20th twentieth\n",
      "    mid-19th thousandth 350th sixteenth 701st ...\n",
      "PN: pronoun, nominal\n",
      "    none something everything one anyone nothing nobody everybody everyone\n",
      "    anybody anything someone no-one nothin\n",
      "PN$: pronoun, nominal, genitive\n",
      "    one's someone's anybody's nobody's everybody's anyone's everyone's\n",
      "PN+BEZ: pronoun, nominal + verb 'to be', present tense, 3rd person singular\n",
      "    nothing's everything's somebody's nobody's someone's\n",
      "PN+HVD: pronoun, nominal + verb 'to have', past tense\n",
      "    nobody'd\n",
      "PN+HVZ: pronoun, nominal + verb 'to have', present tense, 3rd person singular\n",
      "    nobody's somebody's one's\n",
      "PN+MD: pronoun, nominal + modal auxillary\n",
      "    someone'll somebody'll anybody'd\n",
      "PP$: determiner, possessive\n",
      "    our its his their my your her out thy mine thine\n",
      "PP$$: pronoun, possessive\n",
      "    ours mine his hers theirs yours\n",
      "PPL: pronoun, singular, reflexive\n",
      "    itself himself myself yourself herself oneself ownself\n",
      "PPLS: pronoun, plural, reflexive\n",
      "    themselves ourselves yourselves\n",
      "PPO: pronoun, personal, accusative\n",
      "    them it him me us you 'em her thee we'uns\n",
      "PPS: pronoun, personal, nominative, 3rd person singular\n",
      "    it he she thee\n",
      "PPS+BEZ: pronoun, personal, nominative, 3rd person singular + verb 'to be', present tense, 3rd person singular\n",
      "    it's he's she's\n",
      "PPS+HVD: pronoun, personal, nominative, 3rd person singular + verb 'to have', past tense\n",
      "    she'd he'd it'd\n",
      "PPS+HVZ: pronoun, personal, nominative, 3rd person singular + verb 'to have', present tense, 3rd person singular\n",
      "    it's he's she's\n",
      "PPS+MD: pronoun, personal, nominative, 3rd person singular + modal auxillary\n",
      "    he'll she'll it'll he'd it'd she'd\n",
      "PPSS: pronoun, personal, nominative, not 3rd person singular\n",
      "    they we I you ye thou you'uns\n",
      "PPSS+BEM: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 1st person singular\n",
      "    I'm Ahm\n",
      "PPSS+BER: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    we're you're they're\n",
      "PPSS+BEZ: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular\n",
      "    you's\n",
      "PPSS+BEZ*: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular, negated\n",
      "    'tain't\n",
      "PPSS+HV: pronoun, personal, nominative, not 3rd person singular + verb 'to have', uninflected present tense\n",
      "    I've we've they've you've\n",
      "PPSS+HVD: pronoun, personal, nominative, not 3rd person singular + verb 'to have', past tense\n",
      "    I'd you'd we'd they'd\n",
      "PPSS+MD: pronoun, personal, nominative, not 3rd person singular + modal auxillary\n",
      "    you'll we'll I'll we'd I'd they'll they'd you'd\n",
      "PPSS+VB: pronoun, personal, nominative, not 3rd person singular + verb 'to verb', uninflected present tense\n",
      "    y'know\n",
      "QL: qualifier, pre\n",
      "    well less very most so real as highly fundamentally even how much\n",
      "    remarkably somewhat more completely too thus ill deeply little overly\n",
      "    halfway almost impossibly far severly such ...\n",
      "QLP: qualifier, post\n",
      "    indeed enough still 'nuff\n",
      "RB: adverb\n",
      "    only often generally also nevertheless upon together back newly no\n",
      "    likely meanwhile near then heavily there apparently yet outright fully\n",
      "    aside consistently specifically formally ever just ...\n",
      "RB$: adverb, genitive\n",
      "    else's\n",
      "RB+BEZ: adverb + verb 'to be', present tense, 3rd person singular\n",
      "    here's there's\n",
      "RB+CS: adverb + conjunction, coordinating\n",
      "    well's soon's\n",
      "RBR: adverb, comparative\n",
      "    further earlier better later higher tougher more harder longer sooner\n",
      "    less faster easier louder farther oftener nearer cheaper slower tighter\n",
      "    lower worse heavier quicker ...\n",
      "RBR+CS: adverb, comparative + conjunction, coordinating\n",
      "    more'n\n",
      "RBT: adverb, superlative\n",
      "    most best highest uppermost nearest brightest hardest fastest deepest\n",
      "    farthest loudest ...\n",
      "RN: adverb, nominal\n",
      "    here afar then\n",
      "RP: adverb, particle\n",
      "    up out off down over on in about through across after\n",
      "RP+IN: adverb, particle + preposition\n",
      "    out'n outta\n",
      "TO: infinitival to\n",
      "    to t'\n",
      "TO+VB: infinitival to + verb, infinitive\n",
      "    t'jawn t'lah\n",
      "UH: interjection\n",
      "    Hurrah bang whee hmpf ah goodbye oops oh-the-pain-of-it ha crunch say\n",
      "    oh why see well hello lo alas tarantara rum-tum-tum gosh hell keerist\n",
      "    Jesus Keeeerist boy c'mon 'mon goddamn bah hoo-pig damn ...\n",
      "VB: verb, base: uninflected present, imperative or infinitive\n",
      "    investigate find act follow inure achieve reduce take remedy re-set\n",
      "    distribute realize disable feel receive continue place protect\n",
      "    eliminate elaborate work permit run enter force ...\n",
      "VB+AT: verb, base: uninflected present or infinitive + article\n",
      "    wanna\n",
      "VB+IN: verb, base: uninflected present, imperative or infinitive + preposition\n",
      "    lookit\n",
      "VB+JJ: verb, base: uninflected present, imperative or infinitive + adjective\n",
      "    die-dead\n",
      "VB+PPO: verb, uninflected present tense + pronoun, personal, accusative\n",
      "    let's lemme gimme\n",
      "VB+RP: verb, imperative + adverbial particle\n",
      "    g'ahn c'mon\n",
      "VB+TO: verb, base: uninflected present, imperative or infinitive + infinitival to\n",
      "    wanta wanna\n",
      "VB+VB: verb, base: uninflected present, imperative or infinitive; hypenated pair\n",
      "    say-speak\n",
      "VBD: verb, past tense\n",
      "    said produced took recommended commented urged found added praised\n",
      "    charged listed became announced brought attended wanted voted defeated\n",
      "    received got stood shot scheduled feared promised made ...\n",
      "VBG: verb, present participle or gerund\n",
      "    modernizing improving purchasing Purchasing lacking enabling pricing\n",
      "    keeping getting picking entering voting warning making strengthening\n",
      "    setting neighboring attending participating moving ...\n",
      "VBG+TO: verb, present participle + infinitival to\n",
      "    gonna\n",
      "VBN: verb, past participle\n",
      "    conducted charged won received studied revised operated accepted\n",
      "    combined experienced recommended effected granted seen protected\n",
      "    adopted retarded notarized selected composed gotten printed ...\n",
      "VBN+TO: verb, past participle + infinitival to\n",
      "    gotta\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    deserves believes receives takes goes expires says opposes starts\n",
      "    permits expects thinks faces votes teaches holds calls fears spends\n",
      "    collects backs eliminates sets flies gives seeks reads ...\n",
      "WDT: WH-determiner\n",
      "    which what whatever whichever whichever-the-hell\n",
      "WDT+BER: WH-determiner + verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    what're\n",
      "WDT+BER+PP: WH-determiner + verb 'to be', present, 2nd person singular or all persons plural + pronoun, personal, nominative, not 3rd person singular\n",
      "    whaddya\n",
      "WDT+BEZ: WH-determiner + verb 'to be', present tense, 3rd person singular\n",
      "    what's\n",
      "WDT+DO+PPS: WH-determiner + verb 'to do', uninflected present tense + pronoun, personal, nominative, not 3rd person singular\n",
      "    whaddya\n",
      "WDT+DOD: WH-determiner + verb 'to do', past tense\n",
      "    what'd\n",
      "WDT+HVZ: WH-determiner + verb 'to have', present tense, 3rd person singular\n",
      "    what's\n",
      "WP$: WH-pronoun, genitive\n",
      "    whose whosever\n",
      "WPO: WH-pronoun, accusative\n",
      "    whom that who\n",
      "WPS: WH-pronoun, nominative\n",
      "    that who whoever whosoever what whatsoever\n",
      "WPS+BEZ: WH-pronoun, nominative + verb 'to be', present, 3rd person singular\n",
      "    that's who's\n",
      "WPS+HVD: WH-pronoun, nominative + verb 'to have', past tense\n",
      "    who'd\n",
      "WPS+HVZ: WH-pronoun, nominative + verb 'to have', present tense, 3rd person singular\n",
      "    who's that's\n",
      "WPS+MD: WH-pronoun, nominative + modal auxillary\n",
      "    who'll that'd who'd that'll\n",
      "WQL: WH-qualifier\n",
      "    however how\n",
      "WRB: WH-adverb\n",
      "    however when where why whereby wherever how whenever whereon wherein\n",
      "    wherewith wheare wherefore whereof howsabout\n",
      "WRB+BER: WH-adverb + verb 'to be', present, 2nd person singular or all persons plural\n",
      "    where're\n",
      "WRB+BEZ: WH-adverb + verb 'to be', present, 3rd person singular\n",
      "    how's where's\n",
      "WRB+DO: WH-adverb + verb 'to do', present, not 3rd person singular\n",
      "    howda\n",
      "WRB+DOD: WH-adverb + verb 'to do', past tense\n",
      "    where'd how'd\n",
      "WRB+DOD*: WH-adverb + verb 'to do', past tense, negated\n",
      "    whyn't\n",
      "WRB+DOZ: WH-adverb + verb 'to do', present tense, 3rd person singular\n",
      "    how's\n",
      "WRB+IN: WH-adverb + preposition\n",
      "    why'n\n",
      "WRB+MD: WH-adverb + modal auxillary\n",
      "    where'd\n"
     ]
    }
   ],
   "source": [
    "brown_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, singular, common\n",
      "    failure burden court fire appointment awarding compensation Mayor\n",
      "    interim committee fact effect airport management surveillance jail\n",
      "    doctor intern extern night weekend duty legislation Tax Office ...\n",
      "NN$: noun, singular, common, genitive\n",
      "    season's world's player's night's chapter's golf's football's\n",
      "    baseball's club's U.'s coach's bride's bridegroom's board's county's\n",
      "    firm's company's superintendent's mob's Navy's ...\n",
      "NN+BEZ: noun, singular, common + verb 'to be', present tense, 3rd person singular\n",
      "    water's camera's sky's kid's Pa's heat's throat's father's money's\n",
      "    undersecretary's granite's level's wife's fat's Knife's fire's name's\n",
      "    hell's leg's sun's roulette's cane's guy's kind's baseball's ...\n",
      "NN+HVD: noun, singular, common + verb 'to have', past tense\n",
      "    Pa'd\n",
      "NN+HVZ: noun, singular, common + verb 'to have', present tense, 3rd person singular\n",
      "    guy's Knife's boat's summer's rain's company's\n",
      "NN+IN: noun, singular, common + preposition\n",
      "    buncha\n",
      "NN+MD: noun, singular, common + modal auxillary\n",
      "    cowhand'd sun'll\n",
      "NN+NN: noun, singular, common, hyphenated pair\n",
      "    stomach-belly\n",
      "NNS: noun, plural, common\n",
      "    irregularities presentments thanks reports voters laws legislators\n",
      "    years areas adjustments chambers $100 bonds courts sales details raises\n",
      "    sessions members congressmen votes polls calls ...\n",
      "NNS$: noun, plural, common, genitive\n",
      "    taxpayers' children's members' States' women's cutters' motorists'\n",
      "    steelmakers' hours' Nations' lawyers' prisoners' architects' tourists'\n",
      "    Employers' secretaries' Rogues' ...\n",
      "NNS+MD: noun, plural, common + modal auxillary\n",
      "    duds'd oystchers'll\n",
      "NP: noun, singular, proper\n",
      "    Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n",
      "    Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n",
      "    Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n",
      "NP$: noun, singular, proper, genitive\n",
      "    Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's\n",
      "    Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's\n",
      "    Shea's Palmer's Arnold's Broglio's ...\n",
      "NP+BEZ: noun, singular, proper + verb 'to be', present tense, 3rd person singular\n",
      "    W.'s Ike's Mack's Jack's Kate's Katharine's Black's Arthur's Seaton's\n",
      "    Buckhorn's Breed's Penny's Rob's Kitty's Blackwell's Myra's Wally's\n",
      "    Lucille's Springfield's Arlene's\n",
      "NP+HVZ: noun, singular, proper + verb 'to have', present tense, 3rd person singular\n",
      "    Bill's Guardino's Celie's Skolman's Crosson's Tim's Wally's\n",
      "NP+MD: noun, singular, proper + modal auxillary\n",
      "    Gyp'll John'll\n",
      "NPS: noun, plural, proper\n",
      "    Chases Aderholds Chapelles Armisteads Lockies Carbones French Marskmen\n",
      "    Toppers Franciscans Romans Cadillacs Masons Blacks Catholics British\n",
      "    Dixiecrats Mississippians Congresses ...\n",
      "NPS$: noun, plural, proper, genitive\n",
      "    Republicans' Orioles' Birds' Yanks' Redbirds' Bucs' Yankees' Stevenses'\n",
      "    Geraghtys' Burkes' Wackers' Achaeans' Dresbachs' Russians' Democrats'\n",
      "    Gershwins' Adventists' Negroes' Catholics' ...\n",
      "NR: noun, singular, adverbial\n",
      "    Friday home Wednesday Tuesday Monday Sunday Thursday yesterday tomorrow\n",
      "    tonight West East Saturday west left east downtown north northeast\n",
      "    southeast northwest North South right ...\n",
      "NR$: noun, singular, adverbial, genitive\n",
      "    Saturday's Monday's yesterday's tonight's tomorrow's Sunday's\n",
      "    Wednesday's Friday's today's Tuesday's West's Today's South's\n",
      "NR+MD: noun, singular, adverbial + modal auxillary\n",
      "    today'll\n",
      "NRS: noun, plural, adverbial\n",
      "    Sundays Mondays Saturdays Wednesdays Souths Fridays\n"
     ]
    }
   ],
   "source": [
    "brown_tagset(\"N.*\")   # 패턴을 지정해서 특정한 태그만 검색해볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tag set 마다 품사의 의미를 다르게 표현함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she', 'UNK'),\n",
       " ('sells', 'UNK'),\n",
       " ('seashells', 'UNK'),\n",
       " ('on', 'UNK'),\n",
       " ('the', 'UNK'),\n",
       " ('seashore', 'UNK')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(result, \"brown_tagset\")    # 태스 셋을 지정할 수 있음(지정하지 않은 경우와 다르게 나타남)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she', 'UNK'),\n",
       " ('sells', 'UNK'),\n",
       " ('seashells', 'UNK'),\n",
       " ('on', 'UNK'),\n",
       " ('the', 'UNK'),\n",
       " ('seashore', 'UNK')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(result, \"upenn_tagset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she\n",
      "sells\n",
      "seashells\n",
      "skipped: on\n",
      "skipped: the\n",
      "seashore\n",
      "['she', 'sells', 'seashells', 'seashore']\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for term in pos_tag(result):\n",
    "    if term[1] in [\"IN\", \"DT\"]:    # IN: preposition or conjunction, subordinating,  DT: determiner\n",
    "        print(\"skipped:\", term[0])\n",
    "    else:\n",
    "        print(term[0])\n",
    "        tags.append(term[0].lower())\n",
    "        \n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### untag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import untag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escape: .\n",
      "['the', 'little', 'yellow', 'dog', 'barked', 'at', 'the', 'persian', 'cat']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The little yellow dog barked at the Persian cat.\"\n",
    "\n",
    "pattern = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "pattern.sub(\"\", sentence)   # 구두점 제거됨\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "result = []\n",
    "\n",
    "for token in tokens:\n",
    "    if pattern.search(token):\n",
    "        print(\"escape:\", token)\n",
    "    else:\n",
    "        result.append(token.lower())\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = pos_tag(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('yellow', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('persian', 'JJ'),\n",
       " ('cat', 'NN')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'little', 'yellow', 'dog', 'barked', 'at', 'the', 'persian', 'cat']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untag(tagged)\n",
    "#[tag[0] for tag in tagged]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FreqDist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tag set을 dictionary 형태로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('the', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('yellow', 'JJ'),\n",
       "  ('dog', 'NN'),\n",
       "  ('barked', 'VBD'),\n",
       "  ('at', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('persian', 'JJ'),\n",
       "  ('cat', 'NN')],\n",
       " ['the/DT',\n",
       "  'little/JJ',\n",
       "  'yellow/JJ',\n",
       "  'dog/NN',\n",
       "  'barked/VBD',\n",
       "  'at/IN',\n",
       "  'the/DT',\n",
       "  'persian/JJ',\n",
       "  'cat/NN'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged, [\"/\".join(tag) for tag in tagged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('the', 'DT'): 2, ('little', 'JJ'): 1, ('yellow', 'JJ'): 1, ('dog', 'NN'): 1, ('barked', 'VBD'): 1, ('at', 'IN'): 1, ('persian', 'JJ'): 1, ('cat', 'NN'): 1})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textObj = Text(tagged)\n",
    "textObj.vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('persian', 'JJ'), ('cat', 'NN')])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textObj.vocab().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0.2222222222222222)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textObj.vocab().N(), textObj.vocab().freq(('the', 'DT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped: ('the', 'DT')\n"
     ]
    }
   ],
   "source": [
    "# 고빈도 단어 skip\n",
    "for key in textObj.vocab().keys():\n",
    "    if textObj.vocab().freq(key) > 0.2:    # frequency는 비율\n",
    "        print(\"skipped:\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(textObj.vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist   # 단어 빈도 관련 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FreqDist({('the', 'DT'): 2}), 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedTerms = FreqDist()\n",
    "\n",
    "for key in textObj.vocab().keys():\n",
    "    if key[1].startswith(\"DT\"):\n",
    "        taggedTerms[key] = textObj.vocab().get(key)\n",
    "\n",
    "taggedTerms, taggedTerms.N()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 두 코드는 동일함 (FreqDist에는 일부 메서드가 추가로 제공됨) : key, value 쌍으로 이루어진 dictionary\n",
    "\n",
    "~~~\n",
    "from nltk.probability import FreqDist\n",
    "taggedTerms = FreqDist()\n",
    "~~~\n",
    "\n",
    "~~~\n",
    "taggedTerms = defaultdict(int)\n",
    "from collections import defaultdict\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
