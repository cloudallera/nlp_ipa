{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#import\" data-toc-modified-id=\"import-1\">import</a></span></li><li><span><a href=\"#함수-체크\" data-toc-modified-id=\"함수-체크-2\">함수 체크</a></span><ul class=\"toc-item\"><li><span><a href=\"#get_lexicon()\" data-toc-modified-id=\"get_lexicon()-2.1\">get_lexicon()</a></span></li><li><span><a href=\"#get_tfidf_from_konlpy()\" data-toc-modified-id=\"get_tfidf_from_konlpy()-2.2\">get_tfidf_from_konlpy()</a></span></li><li><span><a href=\"#get_tfidf_from_nltk()\" data-toc-modified-id=\"get_tfidf_from_nltk()-2.3\">get_tfidf_from_nltk()</a></span></li><li><span><a href=\"#Extend-Lexicon\" data-toc-modified-id=\"Extend-Lexicon-2.4\">Extend Lexicon</a></span></li></ul></li><li><span><a href=\"#inverted-index-with-tf\" data-toc-modified-id=\"inverted-index-with-tf-3\">inverted index with tf</a></span></li><li><span><a href=\"#dtm-tdm-twm\" data-toc-modified-id=\"dtm-tdm-twm-4\">dtm-tdm-twm</a></span></li><li><span><a href=\"#evaluate-idf\" data-toc-modified-id=\"evaluate-idf-5\">evaluate idf</a></span></li><li><span><a href=\"#numpy를-활용한-info_retrieval.py-성능-개선\" data-toc-modified-id=\"numpy를-활용한-info_retrieval.py-성능-개선-6\">numpy를 활용한 info_retrieval.py 성능 개선</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf,-idf\" data-toc-modified-id=\"tf,-idf-6.1\">tf, idf</a></span></li><li><span><a href=\"#collection,-clean_collection\" data-toc-modified-id=\"collection,-clean_collection-6.2\">collection, clean_collection</a></span></li><li><span><a href=\"#tf-idf-...\" data-toc-modified-id=\"tf-idf-...-6.3\">tf-idf ...</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.info_retrieval import get_lexicon\n",
    "from functions.info_retrieval import get_tfidf_from_konlpy\n",
    "from functions.info_retrieval import get_tfidf_from_nltk\n",
    "from functions.info_retrieval import clean_collection\n",
    "from functions.info_retrieval import extend_lexicon\n",
    "from functions.info_retrieval import inverted_index_with_tf\n",
    "from functions.info_retrieval import get_tdm_from_dtm\n",
    "from functions.info_retrieval import tdm2twm\n",
    "from functions.info_retrieval import evaluate_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kolaw\n",
    "from konlpy.tag import Okt\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 체크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_lexicon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobill_lexicon = get_lexicon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['행정절차법', '일부개정법률안', '(유선호의원', '대표발의', ')', '의', '안', '번', '호',\n",
       "       '9896', '발의연월일', ':', '2010.', '11.', '15.', '발', '의', '자', ':',\n",
       "       '유선호․강기갑․김효석', '최문순ㆍ최재성ㆍ조영택', '김성곤ㆍ문학진ㆍ백재현', '송민순ㆍ양승조ㆍ신낙균',\n",
       "       '조배숙ㆍ박은수ㆍ정동영', '김춘진ㆍ김재윤ㆍ우윤근', '이성남ㆍ박영선', '의원', '(20인)', '제안이유',\n",
       "       '현행법은', '입법예고와', '행정예고를', '통하여', '정책', '결정', '과정에', '국민', '참',\n",
       "       '여의', '절차를', '규정하고', '있기는', '하나', '실제', '정책', '결정·집행·평가의', '단계',\n",
       "       '에서', '근본적인', '국민', '참여', '규정은', '거의', '없어', '위임입법에', '의하여', '정책',\n",
       "       '결정', '및', '집행', '권한이', '부여되는', '문제점이', '있음.', '따라서', '입법예고',\n",
       "       '이전의', '국민적', '협의절차와', '재입법예고', '규정', '등을', '신설하고,', '당사자', '등의',\n",
       "       '개념을', '명확히', '하여', '당사자의', '신청에', '의한', '청', '문의', '기회를', '보장하는',\n",
       "       '한편,', '법령상의', '일부', '미비점을', '개선․보완함으', '-', '1', '-', '-', '2',\n",
       "       '-', '로써', '실질적인', '국민', '참여의'], dtype='<U32')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobill_lexicon[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolaw_lexicon = get_lexicon(corpus=kolaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['대한민국헌법', '유구한', '역사와', '전통에', '빛나는', '우리', '대한국민은', '3·1운동으로',\n",
       "       '건립된', '대한민국임시정부의', '법통과', '불의에', '항거한', '4·19민주이념을', '계승하고,',\n",
       "       '조국의', '민주개혁과', '평화적', '통일의', '사명에', '입각하여', '정의·인도와', '동포애로써',\n",
       "       '민족의', '단결을', '공고히', '하고,', '모든', '사회적', '폐습과', '불의를', '타파하며,',\n",
       "       '자율과', '조화를', '바탕으로', '자유민주적', '기본질서를', '더욱', '확고히', '하여',\n",
       "       '정치·경제·사회·문화의', '모든', '영역에', '있어서', '각인의', '기회를', '균등히', '하고,',\n",
       "       '능력을', '최고도로', '발휘하게', '하며,', '자유와', '권리에', '따르는', '책임과', '의무를',\n",
       "       '완수하게', '하여,', '안으로는', '국민생활의', '균등한', '향상을', '기하고', '밖으로는',\n",
       "       '항구적인', '세계평화와', '인류공영에', '이바지함으로써', '우리들과', '우리들의', '자손의', '안전과',\n",
       "       '자유와', '행복을', '영원히', '확보할', '것을', '다짐하면서', '1948년', '7월', '12일에',\n",
       "       '제정되고', '8차에', '걸쳐', '개정된', '헌법을', '이제', '국회의', '의결을', '거쳐',\n",
       "       '국민투표에', '의하여', '개정한다.', '제1장', '총강', '제1조', '①', '대한민국은',\n",
       "       '민주공화국이다.'], dtype='<U32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kolaw_lexicon[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_tfidf_from_konlpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents, vectorizer, tfidf = get_tfidf_from_konlpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1809896.txt', '1809897.txt', '1809895.txt', '1809894.txt',\n",
       "       '1809890.txt', '1809891.txt', '1809893.txt', '1809892.txt',\n",
       "       '1809899.txt', '1809898.txt'], dtype='<U11')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<bound method Kkma.morphs of <konlpy.tag._kkma.Kkma object at 0x1a24417cf8>>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['대하', '대학', '더', '더라', '더라도', '데', '델', '도', '도록', '도모', '독점',\n",
       "       '돌보', '동', '동반자', '동안', '동원', '동의', '동참', '되', '두', '둘째', '듣', '들',\n",
       "       '등', '등록', '등하교', '디자인', '따', '따뜻', '따라', '따르', '때', '때문', '또',\n",
       "       '또는', '또한', '라', '라고', '락', '란하', '람ㆍ', '략', '러하', '려', '려는', '력',\n",
       "       '련이', '령', '로', '로서', '로써', '록', '롭', '류', '른', '를', '리', '리트',\n",
       "       '린', '립하', '마', '마련', '마찰', '만', '만들', '많', '말하', '매년', '매매', '매우',\n",
       "       '며', '면', '면서', '면역', '명', '명백', '명시', '명이', '명하', '명확히', '모',\n",
       "       '모델', '모든', '목', '목적', '못', '무', '무부', '무원', '무정부', '무회', '문',\n",
       "       '문의', '문제', '문제점', '문학', '문화', '물론', '물자', '므로', '미', '미만', '미비점',\n",
       "       '미치', '민', '민간', '민사', '및', '바', '바레인', '바탕', '박', '박은수', '밖', '반',\n",
       "       '반려', '반영', '받', '발', '발생', '발의', '발전', '방과', '방문', '방법', '방산',\n",
       "       '방안', '방위', '방지', '방한', '배', '배경', '배상', '배상법', '배숙', '배타적', '백',\n",
       "       '백만', '백성', '백재', '번역본', '번호', '벌', '벌금', '벌칙', '범', '범위', '범죄',\n",
       "       '법', '법령', '법률', '법률안', '법리', '법무부', '법안', '법원', '법의', '법인', '법제',\n",
       "       '법제처', '변', '변경', '변론', '변수', '별', '별도', '병력', '병역법', '보', '보다',\n",
       "       '보살핌', '보상', '보여주', '보완', '보유', '보이', '보장', '보존', '보증', '보하', '보험',\n",
       "       '보험금', '보호', '보호법', '복', '복리', '본금', '본문', '본인', '부', '부과', '부담',\n",
       "       '부당', '부대', '부령', '부모', '부모님', '부문별', '부분', '부여', '부의', '부장', '부족',\n",
       "       '부터', '분', '분담', '분석', '분할', '불', '불공정', '불구', '불구하', '불량', '불법적',\n",
       "       '불편', '불필요', '비', '비대칭', '비례', '비상', '비용', '빈번', '사', '사단', '사람',\n",
       "       '사랑과', '사령관', '사례', '사무', '사무소', '사본', '사실', '사실상', '사업', '사업자',\n",
       "       '사업주', '사용', '사유', '사유서', '사이', '사전', '사정', '사항', '사회', '삭', '삭제',\n",
       "       '산정', '상', '상관없이', '상규', '상당', '상당수', '상대', '상대국', '상대방', '상부',\n",
       "       '상세', '상수', '상위', '상존', '상태', '상표법', '상향', '생', '생략', '생명', '생활',\n",
       "       '서', '서류', '서면', '서명', '서비스', '서상기', '석', '석호', '선', '선교', '선박',\n",
       "       '선발대', '선양', '선진', '선호', '설', '설치법', '성', '성가족', '성격', '성공적', '성남',\n",
       "       '성병', '성사', '성질', '성폭력', '성하', '세', '세로', '세부', '세심', '세의', '셋째',\n",
       "       '소', '소관', '소극적', '소말리', '소송', '소요', '소장', '소재', '소지', '소집', '속성',\n",
       "       '손', '손해', '손해액', '송', '수', '수ㆍ구청장', '수가', '수급', '수급자', '수당', '수렴',\n",
       "       '수리', '수립', '수반', '수식', '수업', '수여', '수역', '수출', '수행', '순', '순조',\n",
       "       '쉽', '승', '승수', '승인', '시', '시ㆍ도지사', '시기', '시설', '시장', '시장ㆍ군수ㆍ구청장',\n",
       "       '시정', '시키', '시행', '시험', '식', '신', '신고', '신상', '신설', '신청', '신청자',\n",
       "       '실', '실시', '실용신안', '실정', '실제', '실질적', '실태', '심', '심결', '심사', '심의',\n",
       "       '심화', '아', '아가', '아니', '아니하', '아동', '아랍', '아부', '아서', '아이', '안',\n",
       "       '안보', '안보리', '안이', '안전', '안전과', '안정적', '않', '알', '알선', '알아보', '애주',\n",
       "       '액', '야', '야기', '약', '양', '양국', '양립', '양육', '어', '어느', '어려움', '어른',\n",
       "       '어서', '어야', '어업', '억', '언어', '업', '업자', '업체', '없', '없애', '었', '에',\n",
       "       '에게', '에서', '여', '여가', '여건', '여기', '여부', '여서', '여성', '여액', '여야',\n",
       "       '여의', '여자', '여전히', '역', '연', '연감', '연락처', '연령', '연수생', '연수원', '연습',\n",
       "       '연월일', '연장', '연평균', '연한', '연합', '열', '열람', '엽', '영', '영선', '영아',\n",
       "       '영업', '영진', '영철', '영해', '영향', '영희', '예', '예고', '예고기', '예규', '예비군',\n",
       "       '예비역', '예산', '예산안', '예상', '예정', '오', '와', '완료', '외', '외교적', '외교통',\n",
       "       '외국', '외국인', '외의', '외형', '요건', '요구', '요약', '요인', '요청', '요하', '욕',\n",
       "       '용', '용례', '용어', '용을', '용의', '우', '우려', '우리', '우수성', '우위', '우윤',\n",
       "       '운', '운영', '운영비', '운용', '울', '원', '원법', '원사', '원하', '원희', '월',\n",
       "       '월급'], dtype='<U10')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_list = np.array(vectorizer.get_feature_names())\n",
    "lexicon_list[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon dictionary\n",
    "lexicon_dict = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1486, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lexicon list에서 dictionary 만들기 (ndarray)\n",
    "lexicon_dict = np.array([[token, idx] for (idx, token) in enumerate(lexicon_list)])\n",
    "lexicon_dict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1486)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tfidf.toarray(), columns=lexicon_list, index=documents)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1809896.txt</th>\n",
       "      <th>1809897.txt</th>\n",
       "      <th>1809895.txt</th>\n",
       "      <th>1809894.txt</th>\n",
       "      <th>1809890.txt</th>\n",
       "      <th>1809891.txt</th>\n",
       "      <th>1809893.txt</th>\n",
       "      <th>1809892.txt</th>\n",
       "      <th>1809899.txt</th>\n",
       "      <th>1809898.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>대하</th>\n",
       "      <td>0.020685</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.009378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대학</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>더</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.033208</td>\n",
       "      <td>0.035516</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>더라</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>더라도</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>데</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>델</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>도</th>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.016270</td>\n",
       "      <td>0.017401</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.010271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>도록</th>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.016939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.006808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>도모</th>\n",
       "      <td>0.007927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>독점</th>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>돌보</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.015979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>동</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>0.014206</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>동반자</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>동안</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>동원</th>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>동의</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>동참</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>되</th>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.014077</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.047795</td>\n",
       "      <td>0.048277</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>0.044436</td>\n",
       "      <td>0.029701</td>\n",
       "      <td>0.023444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>두</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1809896.txt  1809897.txt  1809895.txt  1809894.txt  1809890.txt  \\\n",
       "대하      0.020685     0.023462     0.015092     0.046666     0.003677   \n",
       "대학      0.000000     0.000000     0.000000     0.063109     0.000000   \n",
       "더       0.000000     0.000000     0.000000     0.000000     0.032877   \n",
       "더라      0.000000     0.000000     0.000000     0.000000     0.006575   \n",
       "더라도     0.000000     0.000000     0.000000     0.000000     0.006575   \n",
       "데       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "델       0.000000     0.000000     0.000000     0.000000     0.005905   \n",
       "도       0.003776     0.015419     0.016530     0.000000     0.016108   \n",
       "도록      0.012514     0.000000     0.032869     0.016939     0.000000   \n",
       "도모      0.007927     0.000000     0.000000     0.000000     0.000000   \n",
       "독점      0.009325     0.000000     0.000000     0.000000     0.000000   \n",
       "돌보      0.000000     0.000000     0.000000     0.000000     0.007396   \n",
       "동       0.000000     0.000000     0.000000     0.000000     0.013151   \n",
       "동반자     0.000000     0.012692     0.000000     0.000000     0.000000   \n",
       "동안      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "동원      0.009325     0.000000     0.000000     0.000000     0.000000   \n",
       "동의      0.000000     0.118682     0.000000     0.000000     0.000000   \n",
       "동참      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "되       0.056884     0.014077     0.030183     0.011666     0.047795   \n",
       "두       0.000000     0.000000     0.000000     0.000000     0.007396   \n",
       "\n",
       "     1809891.txt  1809893.txt  1809892.txt  1809899.txt  1809898.txt  \n",
       "대하      0.003714     0.003972     0.002777     0.001291     0.009378  \n",
       "대학      0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "더       0.033208     0.035516     0.024835     0.000000     0.000000  \n",
       "더라      0.006642     0.007103     0.004967     0.000000     0.000000  \n",
       "더라도     0.006642     0.007103     0.004967     0.000000     0.000000  \n",
       "데       0.000000     0.010742     0.000000     0.000000     0.000000  \n",
       "델       0.005965     0.006379     0.004461     0.000000     0.030123  \n",
       "도       0.016270     0.017401     0.009126     0.004243     0.010271  \n",
       "도록      0.000000     0.000000     0.004033     0.005625     0.006808  \n",
       "도모      0.000000     0.009132     0.000000     0.000000     0.000000  \n",
       "독점      0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "돌보      0.007470     0.015979     0.000000     0.000000     0.000000  \n",
       "동       0.013283     0.014206     0.009934     0.000000     0.000000  \n",
       "동반자     0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "동안      0.000000     0.000000     0.000000     0.003493     0.000000  \n",
       "동원      0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "동의      0.000000     0.000000     0.000000     0.000000     0.140150  \n",
       "동참      0.000000     0.000000     0.000000     0.000000     0.025364  \n",
       "되       0.048277     0.051631     0.044436     0.029701     0.023444  \n",
       "두       0.007470     0.000000     0.000000     0.002598     0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T[500:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt_doc, okt_vec, okt_tfidf = get_tfidf_from_konlpy(k_morpheme=Okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1809896.txt', '1809897.txt', '1809895.txt', '1809894.txt',\n",
       "       '1809890.txt', '1809891.txt', '1809893.txt', '1809892.txt',\n",
       "       '1809899.txt', '1809898.txt'], dtype='<U11')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<bound method Okt.morphs of <konlpy.tag._okt.Okt object at 0x1ab9a8eda0>>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['근본', '금', '금고', '금액', '금지', '급', '급속히', '급여', '급증', '급할', '기',\n",
       "       '기간', '기관', '기구', '기능', '기대', '기록', '기본', '기업체', '기여', '기자', '기준',\n",
       "       '기타', '기회', '기획', '기획재정부', '긴급', '긴급히', '긴밀한', '김', '김금래', '김성곤',\n",
       "       '김을동', '김재윤', '김정훈', '김춘진', '김태원', '김학송', '김효석', '까', '까지', '까지로',\n",
       "       '까지를', '까지에', '까지와', '까지의', '까지임', '나', '나성린', '나아가', '나은', '나이',\n",
       "       '나타나는', '난민', '날', '남녀', '내', '내용', '내지', '널리', '녀', '노', '노력',\n",
       "       '노출', '논의', '높이', '누락', '느', '는', '늘어날', '능력', '니', '다', '다고',\n",
       "       '다만', '다시', '다양한', '다음', '단계', '단서', '단순한', '단위', '단정', '단체', '단축',\n",
       "       '달', '달성', '담', '당사자', '당시', '당하는', '당해', '대', '대가', '대령', '대방',\n",
       "       '대비', '대상', '대상자', '대신', '대응', '대입', '대책', '대체', '대칭', '대통령',\n",
       "       '대통령령', '대표', '대하', '대학', '대한', '대해', '더', '델', '도', '도모', '도지사',\n",
       "       '독점', '돌보기', '돌보는', '돌보는데', '동', '동반', '동안', '동원', '동의', '동참', '되',\n",
       "       '되고', '되나', '되는', '되도록', '되어', '되어야', '되어있고', '되었을', '되었음', '되지',\n",
       "       '된', '된다', '될', '됨', '됨에', '두', '두어야', '둘째', '듣도록', '들', '들어야',\n",
       "       '등', '등록', '등하교', '디자인', '따', '따뜻한', '따라', '따라서', '따르면', '따르지',\n",
       "       '따른', '따른다', '때', '때문', '또', '또는', '또한', '라', '라고', '락', '람', '래',\n",
       "       '략', '려', '려는', '력', '련', '령', '령등', '령안', '로', '로서', '로써', '로자',\n",
       "       '록', '롭', '류', '른', '를', '리', '리모', '마', '마련', '마찰', '만', '만들고',\n",
       "       '만원', '만을', '많고', '많은', '말', '매년', '매우', '면', '명', '명백한', '명시',\n",
       "       '명확히', '모델', '모든', '목적', '못', '무', '무부', '문', '문대비', '문의', '문제',\n",
       "       '문제점', '문학사', '문학진', '문화', '물론', '물자', '므', '미', '미만', '미비', '미치게',\n",
       "       '민', '민간', '민방위', '민사소송', '및', '바', '바레인', '바탕', '박영선', '박영아',\n",
       "       '박은수', '밖', '밖에', '반', '반려', '반영', '반하는', '받', '받고', '받는', '받는다고',\n",
       "       '받던', '받아', '받은', '발', '발생', '발의', '발전', '방공', '방과', '방문', '방법',\n",
       "       '방산수', '방안', '방지', '방한', '배', '배경', '배상', '배타', '백만원', '백성운',\n",
       "       '백재현', '번', '번역본', '번호', '벌금', '벌칙', '범위', '범죄', '법', '법령', '법률',\n",
       "       '법률상', '법리', '법무부', '법안', '법원', '법인', '법제처장', '변경', '변론', '변수',\n",
       "       '별', '별도', '병력', '병역법', '보', '보기', '보다', '보살핌이', '보상', '보여주고',\n",
       "       '보여주는', '보완', '보유', '보인다', '보자', '보장', '보존', '보증', '보험', '보험금',\n",
       "       '보호', '복', '복리', '본', '본다', '본문', '본인', '볼', '부', '부과', '부담',\n",
       "       '부당행위', '부대', '부령', '부모', '부모님', '부문', '부분', '부서', '부여', '부족하여',\n",
       "       '부터', '분', '분담', '분석관', '분할', '불', '불공정', '불구', '불량하다고', '불법',\n",
       "       '불편', '불필요하다고', '비', '비례', '비상', '비용', '비자', '빈번', '사', '사단', '사람',\n",
       "       '사랑', '사령관', '사례', '사무소', '사실', '사업', '사업자', '사용', '사유', '사의',\n",
       "       '사이', '사전', '사정', '사정변경', '사학', '사항', '사회', '삭', '삭제', '산', '산정',\n",
       "       '상', '상관없이', '상당', '상당수', '상당한', '상대', '상대방', '상세', '상위', '상의',\n",
       "       '상인', '상존', '상충', '상태', '상표', '상향', '생', '생략', '생명', '생활', '서',\n",
       "       '서는', '서류', '서면', '서비스', '서상기', '선박', '선발', '선양', '선진', '설', '설치',\n",
       "       '성', '성격', '성공', '성매매', '성병', '성사', '성질', '성폭력', '세', '세로', '세부',\n",
       "       '세심', '세이', '셋째', '소', '소관', '소말리아', '소송', '소요', '소재', '소지', '소집',\n",
       "       '속성', '손', '손범규', '손해', '손해배상', '송', '송민순', '수', '수가', '수급', '수당',\n",
       "       '수렴', '수립', '수반', '수생', '수식', '수업', '수여', '수역', '수원', '수출', '수행',\n",
       "       '순', '쉽지', '승인', '시', '시기', '시설', '시장', '시정', '시키는', '시키며', '시행',\n",
       "       '시행일', '시험', '식', '신', '신고', '신낙균', '신상', '신설', '신청', '실', '실시',\n",
       "       '실용신안', '실정', '실제', '실질', '실태', '심', '심결', '심사', '심의', '심화', '아',\n",
       "       '아니', '아니면', '아니하거나', '아니하고', '아니하다', '아니한', '아닌', '아덴만', '아동',\n",
       "       '아동학대', '아랍에미리트', '아부다비', '아인', '안', '안규백', '안기', '안보'],\n",
       "      dtype='<U115')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_lexicon_list = np.array(okt_vec.get_feature_names())\n",
    "okt_lexicon_list[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1669)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_df = pd.DataFrame(okt_tfidf.toarray(), columns=okt_lexicon_list, index=okt_doc)\n",
    "okt_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1809896.txt</th>\n",
       "      <th>1809897.txt</th>\n",
       "      <th>1809895.txt</th>\n",
       "      <th>1809894.txt</th>\n",
       "      <th>1809890.txt</th>\n",
       "      <th>1809891.txt</th>\n",
       "      <th>1809893.txt</th>\n",
       "      <th>1809892.txt</th>\n",
       "      <th>1809899.txt</th>\n",
       "      <th>1809898.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>근본</th>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금고</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금액</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금지</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>급</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036483</td>\n",
       "      <td>0.036988</td>\n",
       "      <td>0.036181</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>급속히</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>급여</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.065899</td>\n",
       "      <td>0.064461</td>\n",
       "      <td>0.056804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>급증</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>급할</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기간</th>\n",
       "      <td>0.026248</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.032146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기관</th>\n",
       "      <td>0.045696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기구</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기능</th>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기대</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기록</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027170</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기본</th>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기업체</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기여</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1809896.txt  1809897.txt  1809895.txt  1809894.txt  1809890.txt  \\\n",
       "근본      0.005375     0.000000     0.000000          0.0     0.000000   \n",
       "금       0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "금고      0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "금액      0.000000     0.000000     0.047136          0.0     0.000000   \n",
       "금지      0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "급       0.000000     0.000000     0.000000          0.0     0.036483   \n",
       "급속히     0.000000     0.011276     0.000000          0.0     0.000000   \n",
       "급여      0.000000     0.000000     0.000000          0.0     0.065000   \n",
       "급증      0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "급할      0.000000     0.000000     0.000000          0.0     0.008125   \n",
       "기       0.000000     0.000000     0.000000          0.0     0.007297   \n",
       "기간      0.026248     0.015016     0.000000          0.0     0.005455   \n",
       "기관      0.045696     0.000000     0.000000          0.0     0.000000   \n",
       "기구      0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "기능      0.010751     0.000000     0.000000          0.0     0.000000   \n",
       "기대      0.000000     0.011276     0.000000          0.0     0.000000   \n",
       "기록      0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "기본      0.007996     0.008386     0.000000          0.0     0.000000   \n",
       "기업체     0.000000     0.000000     0.000000          0.0     0.008125   \n",
       "기여      0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "\n",
       "     1809891.txt  1809893.txt  1809892.txt  1809899.txt  1809898.txt  \n",
       "근본      0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "금       0.000000     0.000000     0.000000     0.005434     0.000000  \n",
       "금고      0.000000     0.000000     0.000000     0.021736     0.000000  \n",
       "금액      0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "금지      0.000000     0.000000     0.000000     0.010868     0.000000  \n",
       "급       0.036988     0.036181     0.031883     0.000000     0.014334  \n",
       "급속히     0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "급여      0.065899     0.064461     0.056804     0.000000     0.000000  \n",
       "급증      0.000000     0.000000     0.000000     0.000000     0.012069  \n",
       "급할      0.008237     0.008058     0.007100     0.000000     0.000000  \n",
       "기       0.007398     0.007236     0.006377     0.003227     0.000000  \n",
       "기간      0.005530     0.005409     0.009534     0.004824     0.032146  \n",
       "기관      0.000000     0.000000     0.000000     0.000000     0.010260  \n",
       "기구      0.000000     0.000000     0.000000     0.000000     0.012069  \n",
       "기능      0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "기대      0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "기록      0.000000     0.000000     0.000000     0.027170     0.000000  \n",
       "기본      0.000000     0.000000     0.000000     0.000000     0.008976  \n",
       "기업체     0.008237     0.008058     0.007100     0.000000     0.000000  \n",
       "기여      0.000000     0.010359     0.000000     0.000000     0.010260  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_df.T[500:520]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_tfidf_from_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_doc, nltk_vec, nltk_tfidf = get_tfidf_from_nltk(corpus=brown, e_tokenize=word_tokenize)\n",
    "#nltk_doc, nltk_vec, nltk_tfidf = get_tfidf_from_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function word_tokenize at 0x1a226199d8>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 62877)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tfidf.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62877,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_pos_tag = np.array(nltk_vec.get_feature_names())\n",
    "nltk_pos_tag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['caleb/np', 'calenda/np', 'calendar/nn', 'calendars/nns',\n",
       "       'calendars/nns-hl', \"calf's-foot/nn\", 'calf/nn', 'calf/nn-tl',\n",
       "       'calfskin/nn', \"calhoun's/np\", 'calhoun/np', 'caliber/nn',\n",
       "       'calibers/nns', 'calibrated/vbn', 'calibrating/vbg',\n",
       "       'calibration/nn', 'calibrations/nns', 'calibre/nn',\n",
       "       'caliche-topped/jj', 'calico/nn', 'calif./np', 'calif./np-hl',\n",
       "       \"california's/np\", 'california/np', 'california/np-tl',\n",
       "       'californians/nps', 'caligula/np', 'calimala/fw-nn-tl',\n",
       "       'calinda/nn', 'caliper/nn', 'calipers/nns', 'caliphs/nns',\n",
       "       'calisthenics/nns', 'call-backs/nns', 'call/nn', 'call/nn-hl',\n",
       "       'call/nn-tl', 'call/vb', 'callable/jj', 'callan/np', 'callas/np',\n",
       "       'called/vbd', 'called/vbn', 'caller/nn', 'callers/nns',\n",
       "       'calligraphers/nns', 'calligraphy/nn', \"callin'/vbg\", 'calling/nn',\n",
       "       'calling/vbg', 'callous/jj', 'calloused/vbn', 'callously/rb',\n",
       "       'callousness/nn', 'calls/nil', 'calls/nns', 'calls/vbz',\n",
       "       'calls/vbz-hl', 'calluses/nns', 'calm/jj', 'calm/nn', 'calm/vb',\n",
       "       'calmed/vbd', 'calmed/vbn', 'calmer/jjr', 'calmer/jjr-nc',\n",
       "       'calmest/jjt', 'calming/vbg', 'calmly/rb', 'calmness/nn',\n",
       "       'caloric/jj', 'calorie-heavy/jj', 'calorie/nn', 'calories/nns',\n",
       "       'calorimeter/nn', 'calorimetric/jj', \"caltech's/np\", 'caltech/np',\n",
       "       'calude/np', 'calumniated/vbn', 'calumny/nn', 'calvary/np',\n",
       "       'calves/nns', 'calves/nns-hl', 'calvin/np', 'calving/vbg',\n",
       "       'calvinist/jj-tl', 'calypso/nn', 'cam/np', 'camaraderie/nn',\n",
       "       'camaret/np', \"cambodia's/np\", 'cambodia/np', 'cambridge/np',\n",
       "       'cambridge/np-tl', 'cambridgeport/np', 'camden/np', 'camden/np-tl',\n",
       "       'came/vbd', 'came/vbd-nc'], dtype='<U36')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_pos_tag[10000:10100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['caleb', 'calenda', 'calendar', 'calendars', 'calendars',\n",
       "       \"calf's-foot\", 'calf', 'calf', 'calfskin', \"calhoun's\", 'calhoun',\n",
       "       'caliber', 'calibers', 'calibrated', 'calibrating', 'calibration',\n",
       "       'calibrations', 'calibre', 'caliche-topped', 'calico', 'calif.',\n",
       "       'calif.', \"california's\", 'california', 'california',\n",
       "       'californians', 'caligula', 'calimala', 'calinda', 'caliper',\n",
       "       'calipers', 'caliphs', 'calisthenics', 'call-backs', 'call',\n",
       "       'call', 'call', 'call', 'callable', 'callan', 'callas', 'called',\n",
       "       'called', 'caller', 'callers', 'calligraphers', 'calligraphy',\n",
       "       \"callin'\", 'calling', 'calling', 'callous', 'calloused',\n",
       "       'callously', 'callousness', 'calls', 'calls', 'calls', 'calls',\n",
       "       'calluses', 'calm', 'calm', 'calm', 'calmed', 'calmed', 'calmer',\n",
       "       'calmer', 'calmest', 'calming', 'calmly', 'calmness', 'caloric',\n",
       "       'calorie-heavy', 'calorie', 'calories', 'calorimeter',\n",
       "       'calorimetric', \"caltech's\", 'caltech', 'calude', 'calumniated',\n",
       "       'calumny', 'calvary', 'calves', 'calves', 'calvin', 'calving',\n",
       "       'calvinist', 'calypso', 'cam', 'camaraderie', 'camaret',\n",
       "       \"cambodia's\", 'cambodia', 'cambridge', 'cambridge',\n",
       "       'cambridgeport', 'camden', 'camden', 'came', 'came'], dtype='<U33')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_lexicon_list = np.array([tag.split(\"/\")[0] for tag in nltk_pos_tag])\n",
    "nltk_lexicon_list[10000:10100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 62877)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_df = pd.DataFrame(nltk_tfidf.toarray(), columns=nltk_lexicon_list, index=nltk_doc)\n",
    "nltk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ca01</th>\n",
       "      <th>ca02</th>\n",
       "      <th>ca03</th>\n",
       "      <th>ca04</th>\n",
       "      <th>ca05</th>\n",
       "      <th>ca06</th>\n",
       "      <th>ca07</th>\n",
       "      <th>ca08</th>\n",
       "      <th>ca09</th>\n",
       "      <th>ca10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miller</th>\n",
       "      <td>0.030602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>0.034157</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>0.062336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modernizing</th>\n",
       "      <td>0.014350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monday</th>\n",
       "      <td>0.044361</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.062596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.016727</td>\n",
       "      <td>0.008939</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>0.008887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most</th>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.019353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs.</th>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>0.018380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-million-dollar</th>\n",
       "      <td>0.014350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>must</th>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.016196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near</th>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nevertheless</th>\n",
       "      <td>0.007172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.019282</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.018233</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.022674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newly</th>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next</th>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.028625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.013371</td>\n",
       "      <td>0.010325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0.005902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.012442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ca01      ca02      ca03      ca04      ca05  \\\n",
       "miller                0.030602  0.000000  0.000000  0.000000  0.000000   \n",
       "million               0.034157  0.019440  0.062336  0.000000  0.000000   \n",
       "modernizing           0.014350  0.000000  0.000000  0.000000  0.000000   \n",
       "monday                0.044361  0.008416  0.000000  0.000000  0.000000   \n",
       "money                 0.010540  0.009998  0.005343  0.000000  0.000000   \n",
       "more                  0.008817  0.016727  0.008939  0.013339  0.022085   \n",
       "most                  0.003494  0.003315  0.003543  0.007930  0.003751   \n",
       "mrs.                  0.006079  0.000000  0.000000  0.000000  0.000000   \n",
       "multi-million-dollar  0.014350  0.000000  0.000000  0.000000  0.000000   \n",
       "must                  0.009641  0.003048  0.000000  0.007293  0.013800   \n",
       "names                 0.007527  0.000000  0.000000  0.000000  0.008081   \n",
       "near                  0.010147  0.000000  0.000000  0.000000  0.000000   \n",
       "nevertheless          0.007172  0.000000  0.007271  0.008138  0.000000   \n",
       "new                   0.019282  0.003048  0.013033  0.018233  0.003450   \n",
       "newly                 0.009677  0.000000  0.000000  0.000000  0.000000   \n",
       "next                  0.004535  0.004302  0.004598  0.000000  0.009736   \n",
       "night                 0.018934  0.000000  0.004799  0.000000  0.010163   \n",
       "no                    0.007683  0.002429  0.007790  0.020342  0.005499   \n",
       "no                    0.005902  0.000000  0.000000  0.000000  0.006335   \n",
       "none                  0.012442  0.000000  0.006307  0.000000  0.000000   \n",
       "\n",
       "                          ca06      ca07      ca08      ca09      ca10  \n",
       "miller                0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "million               0.020443  0.000000  0.037836  0.000000  0.013771  \n",
       "modernizing           0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "monday                0.026549  0.009197  0.000000  0.009264  0.062596  \n",
       "money                 0.000000  0.000000  0.005837  0.000000  0.000000  \n",
       "more                  0.002932  0.015234  0.006511  0.012275  0.008887  \n",
       "most                  0.000000  0.003622  0.019353  0.000000  0.000000  \n",
       "mrs.                  0.018190  0.000000  0.000000  0.006347  0.018380  \n",
       "multi-million-dollar  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "must                  0.009617  0.000000  0.003560  0.003356  0.016196  \n",
       "names                 0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "near                  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "nevertheless          0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "new                   0.009617  0.009995  0.010680  0.010067  0.022674  \n",
       "newly                 0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "next                  0.000000  0.000000  0.005023  0.000000  0.013712  \n",
       "night                 0.014165  0.004907  0.000000  0.004942  0.028625  \n",
       "no                    0.007664  0.010620  0.005674  0.013371  0.010325  \n",
       "no                    0.000000  0.000000  0.006537  0.000000  0.000000  \n",
       "none                  0.000000  0.000000  0.006891  0.000000  0.006270  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = nltk_df[\"ca01\":\"ca10\"].T\n",
    "df_new[df_new[\"ca01\"] >0][500:520]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## inverted index with tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "collection = [\n",
    "    (\"Document1\", \"This is a sample\"),\n",
    "    (\"Document2\", \"This is another sample\"),\n",
    "    (\"Document3\", \"This is not sample\"),\n",
    "    (\"Document4\", \"a not\"),\n",
    "    (\"Document5\", \"not\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Document1', ['This', 'is', 'a', 'sample']),\n",
       " ('Document2', ['This', 'is', 'another', 'sample']),\n",
       " ('Document3', ['This', 'is', 'not', 'sample']),\n",
       " ('Document4', ['a', 'not']),\n",
       " ('Document5', ['not'])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_collection = []\n",
    "for filename, content in collection:\n",
    "    splited_content = []\n",
    "    for token in content.split():\n",
    "        splited_content.append(token)\n",
    "    extended_collection.append((filename, splited_content))\n",
    "extended_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'This': 8, 'is': 9, 'a': 12, 'sample': 11, 'another': 6, 'not': 14}\n",
      "['Document1', 'Document2', 'Document3', 'Document4', 'Document5']\n",
      "[[0, 0, 1.0, -1], [1, 0, 1.0, -1], [2, 0, 1.0, -1], [3, 0, 1.0, -1], [0, 1, 1.0, 0], [1, 1, 1.0, 1], [4, 1, 1.0, -1], [3, 1, 1.0, 3], [0, 2, 1.0, 4], [1, 2, 1.0, 5], [5, 2, 1.0, -1], [3, 2, 1.0, 7], [2, 3, 1.0, 2], [5, 3, 1.0, 10], [5, 4, 1.0, 13]]\n"
     ]
    }
   ],
   "source": [
    "global_lexicon, global_posting, global_document, dtm = inverted_index_with_tf(extended_collection)\n",
    "print(global_lexicon)\n",
    "print(global_document)\n",
    "print(global_posting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "    Document3    /    TF:1.0    /    Next:4\n",
      "    Document2    /    TF:1.0    /    Next:0\n",
      "    Document1    /    TF:1.0    /    Next:-1\n",
      "is\n",
      "    Document3    /    TF:1.0    /    Next:5\n",
      "    Document2    /    TF:1.0    /    Next:1\n",
      "    Document1    /    TF:1.0    /    Next:-1\n",
      "a\n",
      "    Document4    /    TF:1.0    /    Next:2\n",
      "    Document1    /    TF:1.0    /    Next:-1\n",
      "sample\n",
      "    Document3    /    TF:1.0    /    Next:7\n",
      "    Document2    /    TF:1.0    /    Next:3\n",
      "    Document1    /    TF:1.0    /    Next:-1\n",
      "another\n",
      "    Document2    /    TF:1.0    /    Next:-1\n",
      "not\n",
      "    Document5    /    TF:1.0    /    Next:13\n",
      "    Document4    /    TF:1.0    /    Next:10\n",
      "    Document3    /    TF:1.0    /    Next:-1\n"
     ]
    }
   ],
   "source": [
    "for index_term, posting_idx in global_lexicon.items():\n",
    "    # index_term:단어, posting_idx:위치\n",
    "    print(index_term)\n",
    "    \n",
    "    while True:    # Posting Nexting: -1\n",
    "        if posting_idx == -1:\n",
    "            break\n",
    "            \n",
    "        posting_data = global_posting[posting_idx]\n",
    "        print(\"    {0}    /    TF:{1}    /    Next:{2}\".format(global_document[posting_data[1]], posting_data[2], posting_data[3]))\n",
    "        posting_idx = posting_data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## dtm-tdm-twm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function functions.info_retrieval.inverted_index_with_tf.<locals>.<lambda>()>,\n",
       "            {'Document1': defaultdict(int,\n",
       "                         {'This': 1, 'is': 1, 'a': 1, 'sample': 1}),\n",
       "             'Document2': defaultdict(int,\n",
       "                         {'This': 1, 'is': 1, 'another': 1, 'sample': 1}),\n",
       "             'Document3': defaultdict(int,\n",
       "                         {'This': 1, 'is': 1, 'not': 1, 'sample': 1}),\n",
       "             'Document4': defaultdict(int, {'a': 1, 'not': 1}),\n",
       "             'Document5': defaultdict(int, {'not': 1})})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tdm = get_tdm_from_dtm(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function functions.info_retrieval.get_tdm_from_dtm.<locals>.<lambda>()>,\n",
       "            {'This': defaultdict(int,\n",
       "                         {'Document1': 1, 'Document2': 1, 'Document3': 1}),\n",
       "             'is': defaultdict(int,\n",
       "                         {'Document1': 1, 'Document2': 1, 'Document3': 1}),\n",
       "             'a': defaultdict(int, {'Document1': 1, 'Document4': 1}),\n",
       "             'sample': defaultdict(int,\n",
       "                         {'Document1': 1, 'Document2': 1, 'Document3': 1}),\n",
       "             'another': defaultdict(int, {'Document2': 1}),\n",
       "             'not': defaultdict(int,\n",
       "                         {'Document3': 1, 'Document4': 1, 'Document5': 1})})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function functions.info_retrieval.tdm2twm.<locals>.<lambda>()>,\n",
       "            {'This': defaultdict(float,\n",
       "                         {'Document1': 0.3010299956639812,\n",
       "                          'Document2': 0.3010299956639812,\n",
       "                          'Document3': 0.3010299956639812}),\n",
       "             'is': defaultdict(float,\n",
       "                         {'Document1': 0.3010299956639812,\n",
       "                          'Document2': 0.3010299956639812,\n",
       "                          'Document3': 0.3010299956639812}),\n",
       "             'a': defaultdict(float,\n",
       "                         {'Document1': 0.47712125471966244,\n",
       "                          'Document4': 0.47712125471966244}),\n",
       "             'sample': defaultdict(float,\n",
       "                         {'Document1': 0.3010299956639812,\n",
       "                          'Document2': 0.3010299956639812,\n",
       "                          'Document3': 0.3010299956639812}),\n",
       "             'another': defaultdict(float, {'Document2': 0.7781512503836436}),\n",
       "             'not': defaultdict(float,\n",
       "                         {'Document3': 0.3010299956639812,\n",
       "                          'Document4': 0.3010299956639812,\n",
       "                          'Document5': 0.3010299956639812})})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twm, dvw = tdm2twm(tdm, global_document)\n",
    "twm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function functions.info_retrieval.tdm2twm.<locals>.<lambda>()>,\n",
       "            {'Document1': defaultdict(float,\n",
       "                         {'This': 0.09061905828945654,\n",
       "                          'is': 0.09061905828945654,\n",
       "                          'a': 0.227644691705265,\n",
       "                          'sample': 0.09061905828945654}),\n",
       "             'Document2': defaultdict(float,\n",
       "                         {'This': 0.09061905828945654,\n",
       "                          'is': 0.09061905828945654,\n",
       "                          'sample': 0.09061905828945654,\n",
       "                          'another': 0.6055193684736281}),\n",
       "             'Document3': defaultdict(float,\n",
       "                         {'This': 0.09061905828945654,\n",
       "                          'is': 0.09061905828945654,\n",
       "                          'sample': 0.09061905828945654,\n",
       "                          'not': 0.09061905828945654}),\n",
       "             'Document4': defaultdict(float,\n",
       "                         {'a': 0.227644691705265, 'not': 0.09061905828945654}),\n",
       "             'Document5': defaultdict(float, {'not': 0.09061905828945654})})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## evaluate idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_lexicon_idf, global_document_weight = evaluate_idf(global_lexicon, global_posting, global_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This': 0.3010299956639812,\n",
       " 'is': 0.3010299956639812,\n",
       " 'a': 0.47712125471966244,\n",
       " 'sample': 0.3010299956639812,\n",
       " 'another': 0.7781512503836436,\n",
       " 'not': 0.3010299956639812}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_lexicon_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Document3': 0.3624762331578262,\n",
       " 'Document2': 0.8773765433419978,\n",
       " 'Document1': 0.49950186657363466,\n",
       " 'Document4': 0.3182637499947215,\n",
       " 'Document5': 0.09061905828945654}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_document_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy를 활용한 info_retrieval.py 성능 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import info_retrieval as ir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### tf, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, -1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, -1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5, -1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(a)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.raw_tf(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.33333333, 0.5       , 0.66666667, 0.83333333,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.norm_tf(arr, len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.30103   , 0.47712125, 0.60205999, 0.69897   ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.log_tf(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.log_tf(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.7, 0.8, 0.9, 1. , 0.5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.max_tf(arr, max(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = np.array([1, 2, 10, 9, 6, 5, 0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.69897   , 0.        , 0.04575749, 0.22184875,\n",
       "       0.30103   , 0.        , 0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.raw_idf(df, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04139269, 0.74036269, 0.04139269, 0.08715018, 0.26324143,\n",
       "       0.34242268, 0.        , 0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.smoothig_idf(df, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95424251,  0.60205999,  0.        , -0.95424251, -0.17609126,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.probability_idf(df, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://en.wikipedia.org/wiki/Tf–idf\n",
    "\n",
    "- query_weight 재구현 (아래 document weight와 query weight 관계 참조)\n",
    "\n",
    "![TF_IDF_weight](../images/TF_IDF_weight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### collection, clean_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "collection = [\n",
    "    (\"Document1\", \"This is a sample!!!\"),\n",
    "    (\"Document2\", \"This is another sample???\"),\n",
    "    (\"Document3\", \"This is not sample>>>\"),\n",
    "    (\"Document4\", \"is a not...\"),\n",
    "    (\"Document5\", \"a not\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cleaned_collection = clean_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Document1', 'This is a sample '),\n",
       " ('Document2', 'This is another sample '),\n",
       " ('Document3', 'This is not sample '),\n",
       " ('Document4', 'is a not '),\n",
       " ('Document5', 'a not')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from functions.naver import NewsScraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "news = NewsScraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenames = news.get_filenames(default_path=\"../naver_news\", all_folder=True)\n",
    "def getContent(file):\n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    return content\n",
    "\n",
    "collection = []   # tuple(filename, content)들의 list\n",
    "\n",
    "for filename in filenames:\n",
    "    collection.append((filename.split(\"/\")[-1], getContent(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00-01-0010682284.txt',\n",
       "  '\\n\\n\\n\\n\\n\\n\\n [앵커]불법 병역 면제, 한국 사회의 고질적인 문제 중 하나가  아닐까 싶습니다. 이번엔, 고의로 청각을  일시 마비시켜 병역을  면제받은 전직 국가대표  사이클 선수와  브로커 등이 적발됐습니다.박민철 기자의 보도입니다. [리포트] 4년 전 국가대표 사이클 선수 A씨는 병역 면제 판정을 받았습니다. 청력에 심각한 문제가 있다는 진단 때문이었지만 가짜였습니다. 밀폐된 차 안에서 2시간 가량 응원용 나팔과 자전거 경적을 사용해 일시적으로 청각을 마비시켜 장애 진단서를 발급 받은 겁니다. 같은 수법으로 병역 면제를 받았던 브로커 32살 이 모 씨가 천5백만 원을 받고 이런 수법을 알려줬습니다.이들은 병역을 면제받기 위해 이런 도구를 이용해 소음을 유발시켜 고의로 청력을 떨어뜨렸습니다. 구독자 100만 명을 넘긴 인터넷 게임방송 BJ도 5천만 원을 주고 수법을 배워 범행을 시도했습니다. 병무청은 2011년부터 7년동안 이런 수법으로 병역을 기피한 혐의 등으로 브로커 이 씨를 구속하고 7명을 불구속 입건했습니다. 최근 7년간 청각장애로 군 면제를 받은 천5백 명에 대한 자료도 들여다볼 예정입니다. [김태화/병무청 차장 : \"중앙 신체검사소의 정밀 검사를 강화해 일시적으로 청력을 마비시켰는지 여부를 확인하는 등 검사 시스템을 개선하기로 했습니다.\"] 지난 2012년부터 2018년까지 신검을 통해 병역 면제를 받은 사람은 6천9백58명. 같은 기간 병역법 위반 혐의로 적발된 피의자는 326명입니다. 체중을 속이는 경우가 97건으로 가장 많았고, 정신질환 위장과 고의 문신, 안과질환 위장 등이 뒤를 이었습니다. 여기에 청각 장애 위장이라는 신종 수법까지 발견된만큼, 병무청은 신체검사 전반을 재점검할 계획입니다. KBS 뉴스 박민철입니다.  박민철 기자 (mcpark@kbs.co.kr)▶ [만세 지도] 우리 동네 3.1운동 현장은?▶ 네이버 채널 KBS뉴스 구독! 시원하게 털어드립니다▶ ‘TV보다 ㄹㅇ’ 당신의 진짜 뉴스 ‘케이야’\\n\\n'),\n",
       " ('00-02-0000205407.txt',\n",
       "  '\\n\\n\\n\\n동영상 뉴스\\n\\n\\n\\n\\n\\n\\n[앵커]지난달 북·미 정상회담이 결렬된 것은 강경파인 볼턴 때문이라는 것이 그동안의 정설이었습니다. 그런데 오늘 의외의 취재결과가 나왔습니다. 저희 JTBC 취재결과, 회담 직전 폼페이오 미 국무장관이 \\'결렬 카드\\'를 트럼프 대통령에게 적극적으로 내밀었던 것으로 파악됐습니다.박현주 기자입니다.[기자]북·미 정상회담 결렬 직후 열렸던 트럼프 대통령의 기자회견.1년 전 싱가포르 회담과는 달리 폼페이오 장관이 함께 단상에 올랐습니다.[도널드 트럼프/미국 대통령 (지난달 28일 기자회견) : 저뿐 아니라 폼페이오 장관도 합의문에 서명하지 않는 게 좋다고 생각했습니다.]최근 미국 행정부 관계자들을 만나고 온 외교 소식통은 \"회담 결렬은 폼페이오 장관이 트럼프 대통령에게 제안한 것으로 들었다\"고 말했습니다.그는 \"폼페이오 장관이 존 볼턴 국가안보보좌관보다 더 적극적인 역할을 했다\"고도 했습니다.[도널드 트럼프/미국 대통령 (지난달 28일 기자회견) : 합의문이 준비돼 있었지만 서명하기 적절하지 않다고 생각했습니다.]북·미 협상팀은 합의문을 작성해놓았지만 미국측은 회담장에 원샷 해결법, 단계적 해법, 노딜 카드를 모두 들고 들어간 것으로도 확인됐습니다.하노이 회담 직전 워싱턴에서 열린 관료 회의에서는 \\'결렬\\' 옵션도 실제 논의된 것으로 전해졌습니다.북한도 회담 이후 이런 정황을 파악하고 폼페이오 장관에 대한 책임론을 들고나왔습니다.최선희 부상은 지난 15일 기자회견에서 \"폼페이오 장관과 볼턴 보좌관이 적대감과 불신의 분위기를 만들었다\"고 말했습니다.폼페이오 장관이 결렬 카드를 내민 배경에는 미국 국내 정치적 상황이 작용했다는 분석이 나옵니다.[신범철/아산정책연구원 안보통일센터장 : 트럼프 대통령이 코언 청문회로 인해서 정치적 어려움을 겪는 가운데 북한 문제 관련해서도 잘못된 거래를 했을 경우 정치적 타격이 예상되는 거죠.]상원의원 출마를 준비중인 폼페이오 장관과 트럼프 대통령 모두 단계적 해법은 정치적으로 도움이 되지 않는다는데 뜻을 같이했을 가능성이 나옵니다.(영상디자인 : 정수임)박현주(park.hyunju@jtbc.co.kr) [영상편집: 이지혜]▶ JTBC 기자들의 시청자 미션 수행? [뉴스 미션] / [뉴스룸 다시보기]▶ 확 달라진 \\'뉴스APP\\' 이슈부터 라이브까지 한눈에!Copyright by JTBC(http://jtbc.joins.com) and JTBC Content Hub Co., Ltd. All Rights Reserved. 무단 전재 및 재배포 금지\\n\\t\\n'),\n",
       " ('00-03-0010704904.txt',\n",
       "  '\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t대부분 휴일과 붙여 사용…용산구 \"특혜 아냐\"(서울=연합뉴스) 고현실 기자 = 용산구청에서 사회복무요원으로 근무 중인 그룹 빅뱅의 멤버 탑(본명 최승현)이 다른 복무요원보다 병가를 평균 3배 더 쓴 것으로 파악됐다.    19일 용산구가 김병기 더불어민주당 의원실에 제출한 자료에 따르면 탑은 작년 1월 26일 용산구청 용산공예관에서 복무를 시작한 이래 최근까지 19일의 병가를 냈다. 용산구청에 근무하는 다른 사회복무요원보다 평균 3배 많은 수치다.    병가 일수 중 15일은 추석과 현충일 등 휴일과 붙여 사용했다.     MBC TV \\'뉴스데스크\\'는 이날 리포트에서 \"탑이 추석, 현충일과 붙여서 병가를 쓸 때 진단서를 따로 제출하지 않았다\"며 특혜 의혹을 제기했다.    탑은 MBC에 \"공황장애가 있었다\"고 해명했다.    용산구는 \"필요한 서류를 다 제출받았다\"며 특혜 의혹을 부인했다.    용산구 관계자는 \"하루 병가는 진단서 제출이 의무가 아니다\"라며 \"탑이 병가를 이틀 이상 쓸 경우 진단서를 제출했고, 사유서는 하루 치 병가에도 모두 제출했다\"고 해명했다.    한편 빅뱅의 또 다른 멤버 지드래곤 역시 군 복무 중 과도한 병가 사용으로 논란이 된 바 있다.그룹 빅뱅의 멤버 탑[연합뉴스 자료 사진]    okko@yna.co.kr▶네이버 홈에서 [연합뉴스] 채널 구독하기▶뭐 하고 놀까? #흥  ▶쇼미더뉴스! 오늘 많이 본 뉴스영상\\n\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cleaned_collection = clean_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00-01-0010682284.txt',\n",
       "  '  앵커 불법 병역 면제  한국 사회의 고질적인 문제 중 하나가 아닐까 싶습니다  이번엔  고의로 청각을 일시 마비시켜 병역을 면제받은 전직 국가대표 사이클 선수와 브로커 등이 적발됐습니다 박민철 기자의 보도입니다   리포트  4년 전 국가대표 사이클 선수 A씨는 병역 면제 판정을 받았습니다  청력에 심각한 문제가 있다는 진단 때문이었지만 가짜였습니다  밀폐된 차 안에서 2시간 가량 응원용 나팔과 자전거 경적을 사용해 일시적으로 청각을 마비시켜 장애 진단서를 발급 받은 겁니다  같은 수법으로 병역 면제를 받았던 브로커 32살 이 모 씨가 천5백만 원을 받고 이런 수법을 알려줬습니다 이들은 병역을 면제받기 위해 이런 도구를 이용해 소음을 유발시켜 고의로 청력을 떨어뜨렸습니다  구독자 100만 명을 넘긴 인터넷 게임방송 BJ도 5천만 원을 주고 수법을 배워 범행을 시도했습니다  병무청은 2011년부터 7년동안 이런 수법으로 병역을 기피한 혐의 등으로 브로커 이 씨를 구속하고 7명을 불구속 입건했습니다  최근 7년간 청각장애로 군 면제를 받은 천5백 명에 대한 자료도 들여다볼 예정입니다   김태화 병무청 차장    중앙 신체검사소의 정밀 검사를 강화해 일시적으로 청력을 마비시켰는지 여부를 확인하는 등 검사 시스템을 개선하기로 했습니다 지난 2012년부터 2018년까지 신검을 통해 병역 면제를 받은 사람은 6천9백58명  같은 기간 병역법 위반 혐의로 적발된 피의자는 326명입니다  체중을 속이는 경우가 97건으로 가장 많았고  정신질환 위장과 고의 문신  안과질환 위장 등이 뒤를 이었습니다  여기에 청각 장애 위장이라는 신종 수법까지 발견된만큼  병무청은 신체검사 전반을 재점검할 계획입니다  KBS 뉴스 박민철입니다  박민철 기자       만세 지도  우리 동네  1운동 현장은   네이버 채널 KBS뉴스 구독  시원하게 털어드립니다   TV보다   당신의 진짜 뉴스  케이야  '),\n",
       " ('00-02-0000205407.txt',\n",
       "  ' 동영상 뉴스  앵커 지난달 북 미 정상회담이 결렬된 것은 강경파인 볼턴 때문이라는 것이 그동안의 정설이었습니다  그런데 오늘 의외의 취재결과가 나왔습니다  저희 JTBC 취재결과  회담 직전 폼페이오 미 국무장관이  결렬 카드 를 트럼프 대통령에게 적극적으로 내밀었던 것으로 파악됐습니다 박현주 기자입니다 기자 북 미 정상회담 결렬 직후 열렸던 트럼프 대통령의 기자회견 1년 전 싱가포르 회담과는 달리 폼페이오 장관이 함께 단상에 올랐습니다 도널드 트럼프 미국 대통령  지난달 28일 기자회견    저뿐 아니라 폼페이오 장관도 합의문에 서명하지 않는 게 좋다고 생각했습니다 최근 미국 행정부 관계자들을 만나고 온 외교 소식통은  회담 결렬은 폼페이오 장관이 트럼프 대통령에게 제안한 것으로 들었다 고 말했습니다 그는  폼페이오 장관이 존 볼턴 더 적극적인 역할을 했다 고도 했습니다 도널드 트럼프 미국 대통령  지난달 28일 기자회견    합의문이 준비돼 있었지만 서명하기 적절하지 않다고 생각했습니다 북 미 협상팀은 합의문을 작성해놓았지만 미국측은 회담장에 원샷 해결법  단계적 해법  노딜 카드를 모두 들고 들어간 것으로도 확인됐습니다 하노이 회담 직전 워싱턴에서 열린 관료 회의에서는  결렬  옵션도 실제 논의된 것으로 전해졌습니다 북한도 회담 이후 이런 정황을 파악하고 폼페이오 장관에 대한 책임론을 들고나왔습니다 최선희 부상은 지난 15일 기자회견에서  폼페이오 장관과 볼턴 보좌관이 적대감과 불신의 분위기를 만들었다 고 말했습니다 폼페이오 장관이 결렬 카드를 내민 배경에는 미국 국내 정치적 상황이 작용했다는 분석이 나옵니다 신범철 아산정책연구원 안보통일센터장   트럼프 대통령이 코언 청문회로 인해서 정치적 어려움을 겪는 가운데 북한 문제 관련해서도 잘못된 거래를 했을 경우 정치적 타격이 예상되는 거죠 상원의원 출마를 준비중인 폼페이오 장관과 트럼프 대통령 모두 단계적 해법은 정치적으로 도움이 되지 않는다는데 뜻을 같이했을 가능성이 나옵니다 영상디자인   정수임 박현주 park     영상편집  이지혜   JTBC 기자들의 시청자 미션 수행   뉴스 미션     뉴스룸 다시보기   확 달라진  뉴스APP  이슈부터 라이브까지 한눈에  by JTBC    and JTBC Content Hub Co Ltd  All Rights   무단 전재 및 재배포 금지 '),\n",
       " ('00-03-0010704904.txt',\n",
       "  ' 대부분 휴일과 붙여 사용 용산구  특혜 아냐 서울 연합뉴스  고현실 기자   용산구청에서 근무 중인 그룹 빅뱅의 멤버 탑 본명 최승현 이 다른 복무요원보다 병가를 평균 3배 더 쓴 것으로 파악됐다  19일 용산구가 김병기 더불어민주당 의원실에 제출한 자료에 따르면 탑은 작년 1월 26일 용산구청 용산공예관에서 복무를 시작한 이래 최근까지 19일의 병가를 냈다  용산구청에 근무하는 다른 평균 3배 많은 수치다  병가 일수 중 15일은 추석과 현충일 등 휴일과 붙여 사용했다  MBC TV  뉴스데스크 는 이날 리포트에서  탑이 추석  현충일과 붙여서 병가를 쓸 때 진단서를 따로 제출하지 않았다 며 특혜 의혹을 제기했다  탑은 MBC에  공황장애가 있었다 고 해명했다  용산구는  필요한 서류를 다 제출받았다 며 특혜 의혹을 부인했다  용산구 관계자는  하루 병가는 진단서 제출이 의무가 아니다 라며  탑이 병가를 이틀 이상 쓸 경우 진단서를 제출했고  사유서는 하루 치 병가에도 모두 제출했다 고 해명했다  한편 빅뱅의 또 다른 멤버 지드래곤 역시 군 복무 중 과도한 병가 사용으로 논란이 된 바 있다 그룹 빅뱅의 멤버 탑 연합뉴스 자료 사진   네이버 홈에서  연합뉴스  채널 구독하기 뭐 하고 놀까   흥  쇼미더뉴스  오늘 많이 본 뉴스영상 ')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_collection[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
