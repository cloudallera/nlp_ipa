{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CSS-Selector\" data-toc-modified-id=\"CSS-Selector-1\">CSS Selector</a></span></li><li><span><a href=\"#CSS-Selector로-포탈-검색결과에서-제목-추출하기\" data-toc-modified-id=\"CSS-Selector로-포탈-검색결과에서-제목-추출하기-2\">CSS Selector로 포탈 검색결과에서 제목 추출하기</a></span></li><li><span><a href=\"#Crawling\" data-toc-modified-id=\"Crawling-3\">Crawling</a></span></li><li><span><a href=\"#webscraping.com-사이트에서-Crawling-실습\" data-toc-modified-id=\"webscraping.com-사이트에서-Crawling-실습-4\">webscraping.com 사이트에서 Crawling 실습</a></span><ul class=\"toc-item\"><li><span><a href=\"#getUrls()-함수-만들기\" data-toc-modified-id=\"getUrls()-함수-만들기-4.1\">getUrls() 함수 만들기</a></span></li></ul></li><li><span><a href=\"#google-검색결과로-부터-External-Site-Crawling\" data-toc-modified-id=\"google-검색결과로-부터-External-Site-Crawling-5\">google 검색결과로 부터 External Site Crawling</a></span><ul class=\"toc-item\"><li><span><a href=\"#getUrls()-함수-재정의(1)\" data-toc-modified-id=\"getUrls()-함수-재정의(1)-5.1\">getUrls() 함수 재정의(1)</a></span></li><li><span><a href=\"#getUrls()-함수-재정의(2)\" data-toc-modified-id=\"getUrls()-함수-재정의(2)-5.2\">getUrls() 함수 재정의(2)</a></span></li><li><span><a href=\"#crawling-함수-테스트\" data-toc-modified-id=\"crawling-함수-테스트-5.3\">crawling 함수 테스트</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간에 keyboard 인터럽트를 하거나, 출력 결과가 너무 큰 셀들은 코멘트 처리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from functions.download import getDownload\n",
    "from functions.search import getPortalSearchUrl\n",
    "from functions.search import getPortalToDOM\n",
    "\n",
    "from functions.download import get_download\n",
    "from functions.search import get_portal_search_url\n",
    "from functions.search import get_portal_to_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doms = getPortalToDOM(\"파이썬 자습서\")    # (doms[0] == google, doms[1] == naver, doms[2] == daum, doms[3] == nate)\n",
    "google, naver, daum, nate = get_portal_to_dom(\"파이썬 자습서\")   # 4대 포탈에서 지정 문자열을 검색 후 DOM 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_urls = get_portal_search_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_url = portal_urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selector : Tag, ID(#아이디), Class(.class)   --> dom.select(\".class\")\n",
    "- name, name^, name$ 등 이름의 일부로 검색 가능  --> dom.select(\"[name^='이름']\")\n",
    "- div p => find_all(div 찾고, 자손 중에 p 찾기)\n",
    "- div > p => find_all(recursive=False), div 찾고, 바로 아래 자손 중에 p 찾기\n",
    "- div + p => find(div).find_next_sibling(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selector로 포탈 검색결과에서 제목 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 자습서 — Python 3.7.3rc1 documentation https://docs.python.org/ko/3/tutorial/index.html\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서 - 위키책 https://ko.wikibooks.org/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "무료 파이썬 프로그래밍 입문서인 『A Byte of Python』 http://byteofpython-korean.sourceforge.net/byte_of_python.html\n",
      "파이썬 강좌 및 유용한 사이트 모음 : 네이버 블로그 http://blog.naver.com/koromoon/220578871433\n",
      "Visual Studio 자습서 1단계의 Python 프로젝트 만들기 | Microsoft Docs https://docs.microsoft.com/ko-kr/visualstudio/python/tutorial-working-with-python-in-visual-studio-step-01-create-project\n",
      "Python | 자습서, API, SDK, 설명서 | AWS 개발자 센터 - Amazon.com https://aws.amazon.com/ko/developer/language/python/\n",
      "5.2 파이썬(Python) 시작하기 – Computational Thinking http://www.kucomputationalthink.org/index.php/chapter-5/5-2-getting-started-with-python/\n",
      "OOP 파이썬 지향 자습서? - 코드 로그 https://codeday.me/ko/qa/20190314/68135.html\n",
      "[리뷰] 파이썬 코딩 도장 - 브런치 https://brunch.co.kr/@fermat39/44\n",
      "무료 파이썬 자습서, eBook 및 전자책 - Blue Breeze https://bluebreeze.co.kr/833\n"
     ]
    }
   ],
   "source": [
    "# 구글\n",
    "for tag in google.select(\".r > a > h3\"):\n",
    "    print(tag.text, tag.find_parent()[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 자습서 https://blog.naver.com/jhhamm?Redirect=Log&logNo=221415897996\n",
      "[python][ebook] 귀도의 파이썬 자습서(2.5) (한글 EBook) https://blog.naver.com/dev4unet?Redirect=Log&logNo=120193065174\n",
      "자료 - 파이썬 자습서 http://blog.daum.net/skcs4/2382\n",
      "[파이선] 파이썬 자습서 (한글화가 잘 되어 있네요) http://cafe.naver.com/cortexsh/1653\n",
      "파이썬 ve C언어 http://cafe.naver.com/cafec/378766\n",
      "볼만한 파이썬 관련 웹 문서들 http://cafe.naver.com/jjleelab/208\n",
      "[nRF Mesh] Sending mesh packets [2-serial examples] http://cafe.naver.com/cortexsh/1694\n",
      "과학 전공도서/자습서/교양서적 등 팝니다~ http://cafe.naver.com/joonggonara/544995903\n",
      "떠오르는 심층 신경망 API, \"케라스\" 알아보기 http://www.itworld.co.kr/news/116583\n",
      "파이썬, 주류 언어로 부상··· 티오베와 PyPL 지표에서 상위권 http://www.ciokorea.com/news/114426\n",
      "IT전문가를 위한 라즈베리 파이 프로젝트 13선 http://www.ciokorea.com/news/113478\n",
      "개발자 출신 빅토리아시크릿 모델 ... '뇌섹녀' 인증 http://www.fnnews.com/news/201809111029096827\n",
      "기술력 향상을 도울 온라인 무료 교육 사이트 8선 http://www.ciokorea.com/news/38589\n",
      "올해 대학 합격하고 컴퓨터 공학과에 https://kin.naver.com/qna/detail.nhn?d1id=11&dirId=1113&docId=320102309&qb=7YyM7J207I2sIOyekOyKteyEnA==&enc=utf8&section=kin&rank=1&search_sort=0&spq=0\n",
      "경북대학교 소프트웨어학과 진학에 관해서 https://kin.naver.com/qna/detail.nhn?d1id=1&dirId=10405&docId=297058448&qb=7YyM7J207I2sIOyekOyKteyEnA==&enc=utf8&section=kin&rank=2&search_sort=0&spq=0\n",
      "고1 공부법 및 진로 https://kin.naver.com/qna/detail.nhn?d1id=11&dirId=1104&docId=297769561&qb=7YyM7J207I2sIOyekOyKteyEnA==&enc=utf8&section=kin&rank=3&search_sort=0&spq=0\n",
      "The Python Tutorial — Python 3.7.3rc1 documentation https://docs.python.org/3/tutorial/index.html\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서 https://ko.wikibooks.org/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서/재귀 https://ko.wikibooks.org/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C/%EC%9E%AC%EA%B7%80\n"
     ]
    }
   ],
   "source": [
    "# 네이버\n",
    "for tag in naver.select(\".type01 dt\"):\n",
    "    print(tag.a.text, tag.a[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[파이썬기초] 자습서 http://jinbonews.tistory.com/8\n",
      "무료 파이썬 자습서, eBook 및 전자책 http://bluebreeze.co.kr/833\n",
      "[python][ebook] 귀도의 파이썬 자습서(2.5) (한글 EBook) http://blog.naver.com/PostView.nhn?blogId=dev4unet&logNo=120193065174\n",
      "python자습서_ 숫자, 문자열 http://make-it-developer.tistory.com/21\n",
      "파이썬 자습서 ¶ https://docs.python.org/ko/3.7/tutorial/index.html\n",
      "【免費教育APP】파이썬 자습서|線上玩APP不花錢 http://searchapp.soft4fun.net/article/information/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C/4122219\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서/서문 http://ko.m.wikibooks.nym.mx/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C/%EC%84%9C%EB%AC%B8\n",
      "프로그래머가 아닌 이들을 위한 파이썬 3 자습서/FAQ http://ko.m.wikibooks.nom.rs/wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EC%95%84%EB%8B%8C_%EC%9D%B4%EB%93%A4%EC%9D%84_%EC%9C%84%ED%95%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_3_%EC%9E%90%EC%8A%B5%EC%84%9C/FAQ\n",
      "떠오르는 심층 신경망 API, \"케라스\" 알아보기 https://cp.news.search.daum.net/p/76899725\n",
      "파이썬, 주류 언어로 부상··· 티오베와 PyPL 지표에서 상위권 https://cp.news.search.daum.net/p/76900731\n",
      "IT전문가를 위한 라즈베리 파이 프로젝트 13선 https://cp.news.search.daum.net/p/76901247\n",
      "개발자 출신 빅토리아시크릿 모델 .. '뇌섹녀' 인증 http://v.media.daum.net/v/20180911103410467?f=o\n",
      "파이썬 정리 5일차 http://cafe.daum.net/g2G/mHOy/22?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "어떻게 무료로 데이터 과학자가 될 수 있는지((주... http://cafe.daum.net/statsas/OE8F/20?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "Genymtn http://cafe.daum.net/synstar/GDuw/3917?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n",
      "ㅁㅁㅁ http://cafe.daum.net/flowlife/S0Qo/1?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%9E%90%EC%8A%B5%EC%84%9C\n"
     ]
    }
   ],
   "source": [
    "# 다음\n",
    "for tag in daum.select(\".mg_tit > a\"):\n",
    "    print(tag.text.strip(), tag[\"href\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[파이썬기초] 자습서 http://jinbonews.tistory.com/8\n",
      "무료 파이썬 자습서, eBook 및 전자책 http://bluebreeze.co.kr/833\n",
      "[python][ebook] 귀도의 파이썬 자습서(2.5) (한글 EBook) http://blog.naver.com/PostView.nhn?blogId=dev4unet&logNo=120193065174\n",
      "python자습서_ 숫자, 문자열 http://make-it-developer.tistory.com/21\n"
     ]
    }
   ],
   "source": [
    "# 네이트\n",
    "for tag in nate.select(\"div#blogColl .f_link_b\"):\n",
    "    print(tag.text, tag[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<a> 태그에 있는 하이퍼링크를 이용해 웹을 인덱싱 하는 작업을 Crawling 이라 합니다.`\n",
    "\n",
    "이런 작업을 반복적으로 자동으로 수행하는 Agent를 Bot이라고 합니다.\n",
    "\n",
    "`Scrapy`는 Agent를 만들어주는 Framework이고, `BeautifulSoup`은 HTML을 Parsing하는 패키지 입니다.<br>\n",
    "실습에서는 `BeautifulSoup`을 사용 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## webscraping.com 사이트에서 Crawling 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example.webscraping.com/places/default/index 사이트에서 실습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"http://example.webscraping.com/places/default/index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = get_download(seed)\n",
    "dom = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(dom.select(\"a\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://example.webscraping.com/search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from urllib.parse import urljoin\n",
    "from requests.compat import urljoin\n",
    "\n",
    "urljoin(seed, \"/search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: #\n",
      "http://example.webscraping.com/places/default/user/register?_next=/places/default/index\n",
      "http://example.webscraping.com/places/default/user/login?_next=/places/default/index\n",
      "http://example.webscraping.com/places/default/index\n",
      "http://example.webscraping.com/places/default/search\n",
      "http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "http://example.webscraping.com/places/default/view/Albania-3\n",
      "http://example.webscraping.com/places/default/view/Algeria-4\n",
      "http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "http://example.webscraping.com/places/default/view/Andorra-6\n",
      "http://example.webscraping.com/places/default/view/Angola-7\n",
      "http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "http://example.webscraping.com/places/default/index/1\n"
     ]
    }
   ],
   "source": [
    "for tag in dom.select(\"a\"):\n",
    "    if tag.has_attr(\"href\"):\n",
    "        href = tag[\"href\"]\n",
    "        # print(href)\n",
    "        \n",
    "        # URL Normalization\n",
    "        if href.startswith(\"http\"):    # HTTP(S)\n",
    "            print(\"External : {0}\".format(href))\n",
    "        elif href.startswith(\"/\"):\n",
    "            print(urljoin(seed, href))     # internal link 인 경우 서버 주소를 추가해준다.\n",
    "        else:\n",
    "            print(\"Skipped: {0}\".format(href))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = []\n",
    "\n",
    "for tag in dom.select(\"a\"):\n",
    "    if tag.has_attr(\"href\"):\n",
    "        href = tag[\"href\"]\n",
    "        \n",
    "        # URL Normalization\n",
    "        if href.startswith(\"http\"):    # HTTP(S)\n",
    "            print(\"External : {0}\".format(href))\n",
    "        elif href.startswith(\"/\"):\n",
    "            newSeed = urljoin(seed, href)\n",
    "            if newSeed not in unseen:\n",
    "                unseen.append(newSeed)\n",
    "        else:\n",
    "            # print(\"Skipped: {0}\".format(href))\n",
    "            pass\n",
    "        \n",
    "    # print(unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getUrls() 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrls(base):\n",
    "    html = get_download(base)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "    unseen = []\n",
    "\n",
    "    for tag in dom.select(\"a\"):\n",
    "        if tag.has_attr(\"href\"):\n",
    "            href = tag[\"href\"]\n",
    "\n",
    "            # URL Normalization\n",
    "            if href.startswith(\"http\"):    # HTTP(S)\n",
    "                # print(\"External : {0}\".format(href))\n",
    "                pass\n",
    "            elif href.startswith(\"/\"):\n",
    "                newSeed = urljoin(seed, href)\n",
    "                if newSeed not in unseen:\n",
    "                    unseen.append(newSeed)\n",
    "            else:\n",
    "                # print(\"Skipped: {0}\".format(href))\n",
    "                pass\n",
    "                \n",
    "    print(\"{0} --> {1}\".format(base, len(unseen)))\n",
    "    \n",
    "    return unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.webscraping.com/places/default/index --> 15\n"
     ]
    }
   ],
   "source": [
    "queue = getUrls(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import random\n",
    "\n",
    "# while queue:\n",
    "#     seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     time.sleep(random.randint(1, 5))\n",
    "#     unseen = getUrls(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queue = getUrls(seed)\n",
    "\n",
    "# while queue:\n",
    "#     seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     time.sleep(random.randint(1, 5))\n",
    "#     unseen = getUrls(seed)\n",
    "    \n",
    "#     print(\"Q:{0}, Unseen:{1}\".format(len(queue), len(unseen)))\n",
    "#     queue.extend(unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, [3]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "b = [3]\n",
    "a.append(b)    # list 자체가 추가됨\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "b = [3]\n",
    "a.extend(b)    # list 원소를 하나 씩 추출해서 추가함\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queue = getUrls(seed)\n",
    "# seen = []\n",
    "\n",
    "# while queue:\n",
    "#     seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     seen.append(seed)\n",
    "#     time.sleep(random.randint(1, 5))\n",
    "#     unseen = getUrls(seed)\n",
    "    \n",
    "#     print(\"Q:{0}, Unseen:{1}\".format(len(queue), len(unseen)))\n",
    "\n",
    "#     queue.extend([link for link in unseen if link not in seen and queue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## google 검색결과로 부터 External Site Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getUrls() 함수 재정의(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrls(base):\n",
    "    html = get_download(base)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "    unseen = []\n",
    "\n",
    "    for tag in dom.select(\"a\"):\n",
    "        if tag.has_attr(\"href\"):\n",
    "            href = tag[\"href\"]\n",
    "\n",
    "            # URL Normalization\n",
    "            if href.startswith(\"http\"):    # HTTP(S)\n",
    "                if href not in unseen:\n",
    "                    unseen.append(href)\n",
    "\n",
    "            elif href.startswith(\"/\"):\n",
    "                newSeed = urljoin(seed, href)\n",
    "                if newSeed not in unseen:\n",
    "                    unseen.append(newSeed)\n",
    "                    \n",
    "            else:\n",
    "                # print(\"Skipped: {0}\".format(href))\n",
    "                pass\n",
    "                \n",
    "    print(\"{0} --> {1}\".format(base, len(unseen)))\n",
    "    \n",
    "    return unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_url = get_portal_search_url()\n",
    "google_url = portal_url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Python.org https://www.python.org/\n",
      "파이썬 자습서 — Python 3.7.3rc1 documentation https://docs.python.org/ko/3/tutorial/index.html\n",
      "파이썬 - 위키백과, 우리 모두의 백과사전 https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC\n",
      "1. 파이썬 시작하기 - 왕초보를 위한 Python 2.7 - WikiDocs https://wikidocs.net/43\n",
      "Python - 나무위키 https://namu.wiki/w/Python\n",
      "파이썬 입문 | 프로그래머스 https://programmers.co.kr/learn/courses/2\n",
      "Python & Ruby - 생활코딩 https://opentutorials.org/course/1750\n",
      "CS231n 번역 - Python Numpy Tutorial - Team AI Korea http://aikorea.org/cs231n/python-numpy-tutorial/\n",
      "파이썬을 여행하는 히치하이커를 위한 안내서! — The Hitchhiker's ... https://python-guide-kr.readthedocs.io/ko/latest/\n",
      "파이썬 - 人 CoDOM http://www.incodom.kr/%ED%8C%8C%EC%9D%B4%EC%8D%AC\n"
     ]
    }
   ],
   "source": [
    "html = get_download(google_url, {\"q\": \"파이썬\"})\n",
    "dom = BeautifulSoup(html.text, \"lxml\")\n",
    "\n",
    "queue = []\n",
    "\n",
    "for tag in dom.select(\".r > a > h3\"):\n",
    "    href = tag.find_parent()[\"href\"]\n",
    "    print(tag.text, href)\n",
    "    queue.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " ['https://www.python.org/',\n",
       "  'https://docs.python.org/ko/3/tutorial/index.html',\n",
       "  'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC',\n",
       "  'https://wikidocs.net/43',\n",
       "  'https://namu.wiki/w/Python',\n",
       "  'https://programmers.co.kr/learn/courses/2',\n",
       "  'https://opentutorials.org/course/1750',\n",
       "  'http://aikorea.org/cs231n/python-numpy-tutorial/',\n",
       "  'https://python-guide-kr.readthedocs.io/ko/latest/',\n",
       "  'http://www.incodom.kr/%ED%8C%8C%EC%9D%B4%EC%8D%AC'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queue), queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for link in queue:\n",
    "#     html = get_download(link)\n",
    "#     dom = BeautifulSoup(html.text, \"lxml\")\n",
    "#     for a in dom.select(\"a\"):\n",
    "#         if a.has_attr(\"href\"):\n",
    "#             if a[\"href\"].startswith(\"http\"):\n",
    "#                 print(a[\"href\"])\n",
    "#             elif a[\"href\"].startswith(\"/\") and len(a[\"href\"]) > 1:\n",
    "#                 print(urljoin(link, a[\"href\"]))\n",
    "#             else:\n",
    "#                 print(\"Skipped: {0}\".format(a[\"href\"]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.python.org/ --> 190\n",
      "https://docs.python.org/ko/3/tutorial/index.html --> 6\n",
      "https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC --> 499\n",
      "https://wikidocs.net/43 --> 4\n",
      "https://namu.wiki/w/Python --> 437\n",
      "https://programmers.co.kr/learn/courses/2 --> 161\n",
      "https://opentutorials.org/course/1750 --> 144\n",
      "http://aikorea.org/cs231n/python-numpy-tutorial/ --> 37\n",
      "https://python-guide-kr.readthedocs.io/ko/latest/ --> 26\n",
      "http://www.incodom.kr/%ED%8C%8C%EC%9D%B4%EC%8D%AC --> 105\n"
     ]
    }
   ],
   "source": [
    "for link in queue:\n",
    "    links = []\n",
    "    html = get_download(link)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "    for a in dom.select(\"a\"):\n",
    "        if a.has_attr(\"href\"):\n",
    "            if a[\"href\"].startswith(\"http\"):\n",
    "                links.append(a[\"href\"])\n",
    "            elif a[\"href\"].startswith(\"/\") and len(a[\"href\"]) > 1:\n",
    "                links.append(urljoin(link, a[\"href\"]))\n",
    "            else:\n",
    "                pass\n",
    "                # print(\"Skipped: {0}\".format(a[\"href\"]))\n",
    "    print(\"{0} --> {1}\".format(link, len(links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getUrls() 함수 재정의(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getUrls(link, depth=3):\n",
    "    if depth > 3:\n",
    "        return None\n",
    "    \n",
    "    links = []\n",
    "    html = get_download(link)\n",
    "    dom = BeautifulSoup(html.text, \"lxml\")\n",
    "\n",
    "    for a in dom.select(\"a\"):\n",
    "        if a.has_attr(\"href\"):\n",
    "            if a[\"href\"].startswith(\"http\"):\n",
    "                links.append({\"url\": a[\"href\"], \"depth\": depth+1})\n",
    "            elif a[\"href\"].startswith(\"/\") and len(a[\"href\"]) > 1:\n",
    "                links.append({\"url\": urljoin(link, a[\"href\"]), \"depth\": depth+1})\n",
    "            else:\n",
    "                pass\n",
    "                # print(\"Skipped: {0}\".format(a[\"href\"]))\n",
    "    print(\"{0} {1} -> {2}\".format(\">\" * (depth+1), link, len(links)))\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = get_download(google_url, {\"q\": \"파이썬\"})\n",
    "dom = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = []\n",
    "\n",
    "for tag in dom.select(\".r > a > h3\"):\n",
    "    href = tag.find_parent()[\"href\"]\n",
    "    queue.append({\"url\": href, \"depth\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.python.org/', 'depth': 0},\n",
       " {'url': 'https://docs.python.org/ko/3/tutorial/index.html', 'depth': 0},\n",
       " {'url': 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC',\n",
       "  'depth': 0},\n",
       " {'url': 'https://wikidocs.net/43', 'depth': 0},\n",
       " {'url': 'https://namu.wiki/w/Python', 'depth': 0},\n",
       " {'url': 'https://programmers.co.kr/learn/courses/2', 'depth': 0},\n",
       " {'url': 'https://opentutorials.org/course/1750', 'depth': 0},\n",
       " {'url': 'http://aikorea.org/cs231n/python-numpy-tutorial/', 'depth': 0},\n",
       " {'url': 'https://python-guide-kr.readthedocs.io/ko/latest/', 'depth': 0},\n",
       " {'url': 'http://www.incodom.kr/%ED%8C%8C%EC%9D%B4%EC%8D%AC', 'depth': 0}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while queue:\n",
    "#     link = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "#     links = getUrls(link[\"url\"], link[\"depth\"])\n",
    "    \n",
    "#     if links != None:\n",
    "#         for newlink in links:\n",
    "#             if newlink not in queue:\n",
    "#                 queue.append({\"url\": newlink[\"url\"], \"depth\": newlink[\"depth\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crawling 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from functions.crawling import getUrls\n",
    "from functions.crawling import get_site_urls   # getUrls 함수명 재정의\n",
    "from functions import crawling\n",
    "from functions.download import get_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = get_download(google_url, {\"q\": \"파이썬\"})\n",
    "dom = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = []\n",
    "\n",
    "for tag in dom.select(\".r > a > h3\"):\n",
    "    href = tag.find_parent()[\"href\"]\n",
    "    queue.append({\"url\": href, \"depth\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.python.org/', 'depth': 0},\n",
       " {'url': 'https://docs.python.org/ko/3/tutorial/index.html', 'depth': 0},\n",
       " {'url': 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC',\n",
       "  'depth': 0},\n",
       " {'url': 'https://wikidocs.net/43', 'depth': 0},\n",
       " {'url': 'https://namu.wiki/w/Python', 'depth': 0},\n",
       " {'url': 'https://programmers.co.kr/learn/courses/2', 'depth': 0},\n",
       " {'url': 'https://opentutorials.org/course/1750', 'depth': 0},\n",
       " {'url': 'http://aikorea.org/cs231n/python-numpy-tutorial/', 'depth': 0},\n",
       " {'url': 'https://python-guide-kr.readthedocs.io/ko/latest/', 'depth': 0},\n",
       " {'url': 'http://www.incodom.kr/%ED%8C%8C%EC%9D%B4%EC%8D%AC', 'depth': 0}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> https://www.facebook.com/pythonlang?fref=ts --> 86개 사이트 추가\n",
      "Queue:2447, Unseen:86\n",
      ">> https://twitter.com/ThePSF --> 113개 사이트 추가\n",
      "Queue:2532, Unseen:113\n",
      ">> https://www.python.org/community/irc/ --> 146개 사이트 추가\n",
      "Queue:2644, Unseen:146\n",
      ">> https://www.python.org/about/ --> 175개 사이트 추가\n",
      "Queue:2789, Unseen:175\n",
      ">> https://www.python.org/about/apps/ --> 184개 사이트 추가\n",
      "Queue:2963, Unseen:184\n",
      ">> https://www.python.org/about/quotes/ --> 156개 사이트 추가\n",
      "Queue:3146, Unseen:156\n",
      ">> https://www.python.org/about/gettingstarted/ --> 160개 사이트 추가\n",
      "Queue:3301, Unseen:160\n",
      ">> https://www.python.org/about/help/ --> 164개 사이트 추가\n",
      "Queue:3460, Unseen:164\n",
      ">> http://brochure.getpython.info/ --> 41개 사이트 추가\n",
      "Queue:3623, Unseen:41\n",
      ">> https://www.python.org/downloads/ --> 514개 사이트 추가\n",
      "Queue:3663, Unseen:514\n",
      ">> https://www.python.org/downloads/ --> 514개 사이트 추가\n",
      "Queue:4176, Unseen:514\n",
      ">> https://www.python.org/downloads/source/ --> 714개 사이트 추가\n",
      "Queue:4689, Unseen:714\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-533606f11d91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#time.sleep(random.randint(1, 3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0munseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_site_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue:{0}, Unseen:{1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ai/NLP/nlp_ipa/functions/crawling.py\u001b[0m in \u001b[0;36mget_site_urls\u001b[0;34m(link, depth)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mdom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getNsTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mnsprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         tag = Tag(self, self.builder, name, namespace, nsprefix, attrs,\n\u001b[0;32m--> 520\u001b[0;31m                   self.currentTag, self._most_recent_element)\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdata_list_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                 attrs = builder._replace_cdata_list_attribute_values(\n\u001b[0;32m--> 902\u001b[0;31m                     self.name, attrs)\n\u001b[0m\u001b[1;32m    903\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                 \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/builder/__init__.py\u001b[0m in \u001b[0;36m_replace_cdata_list_attribute_values\u001b[0;34m(self, tag_name, attrs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             tag_specific = self.cdata_list_attributes.get(\n\u001b[1;32m    162\u001b[0m                 tag_name.lower(), None)\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniversal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtag_specific\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# We have a \"class\"-type attribute whose string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seen = []\n",
    "\n",
    "while queue:\n",
    "    seed = queue.pop(0)    # 맨 앞에 있는 것을 가져옴\n",
    "    seen.append(seed)\n",
    "    #time.sleep(random.randint(1, 3))\n",
    "    unseen = get_site_urls(seed[\"url\"], seed[\"depth\"])\n",
    "    \n",
    "    print(\"Queue:{0}, Unseen:{1}\".format(len(queue), len(unseen)))\n",
    "\n",
    "    queue.extend({\"url\": link[\"url\"], \"depth\": link[\"depth\"]} for link in unseen if link not in seen and queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
