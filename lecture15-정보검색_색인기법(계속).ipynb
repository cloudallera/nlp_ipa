{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#정보검색\" data-toc-modified-id=\"정보검색-1\">정보검색</a></span><ul class=\"toc-item\"><li><span><a href=\"#Theory\" data-toc-modified-id=\"Theory-1.1\">Theory</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1.1.1\">Overview</a></span><ul class=\"toc-item\"><li><span><a href=\"#버지니아공대-정보검색-강좌-:-http://www.cs.virginia.edu/~hw5x/Course/IR2015/_site/lectures/\" data-toc-modified-id=\"버지니아공대-정보검색-강좌-:-http://www.cs.virginia.edu/~hw5x/Course/IR2015/_site/lectures/-1.1.1.1\">버지니아공대 정보검색 강좌 : <a href=\"http://www.cs.virginia.edu/~hw5x/Course/IR2015/_site/lectures/\" target=\"_blank\">http://www.cs.virginia.edu/~hw5x/Course/IR2015/_site/lectures/</a></a></span></li><li><span><a href=\"#How-to-perform-information-retrieval\" data-toc-modified-id=\"How-to-perform-information-retrieval-1.1.1.2\">How to perform information retrieval</a></span></li></ul></li><li><span><a href=\"#Basic-search-engine-architecture\" data-toc-modified-id=\"Basic-search-engine-architecture-1.1.2\">Basic search engine architecture</a></span><ul class=\"toc-item\"><li><span><a href=\"#Abstraction-of-search-engine-architecture\" data-toc-modified-id=\"Abstraction-of-search-engine-architecture-1.1.2.1\">Abstraction of search engine architecture</a></span></li><li><span><a href=\"#One-sentence-about-IR\" data-toc-modified-id=\"One-sentence-about-IR-1.1.2.2\">One sentence about IR</a></span></li><li><span><a href=\"#What-you-should-know\" data-toc-modified-id=\"What-you-should-know-1.1.2.3\">What you should know</a></span></li></ul></li><li><span><a href=\"#Web-Crawling-and-Basic-Text-Analysis\" data-toc-modified-id=\"Web-Crawling-and-Basic-Text-Analysis-1.1.3\">Web Crawling and Basic Text Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-does-it-work\" data-toc-modified-id=\"How-does-it-work-1.1.3.1\">How does it work</a></span></li><li><span><a href=\"#What-you-should-know\" data-toc-modified-id=\"What-you-should-know-1.1.3.2\">What you should know</a></span></li></ul></li></ul></li><li><span><a href=\"#색인기법\" data-toc-modified-id=\"색인기법-1.2\">색인기법</a></span><ul class=\"toc-item\"><li><span><a href=\"#Full-text-indexing-:-Bag-of-Words-representation\" data-toc-modified-id=\"Full-text-indexing-:-Bag-of-Words-representation-1.2.1\">Full text indexing : Bag-of-Words representation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bag-of-Words-representation-구현-절차\" data-toc-modified-id=\"Bag-of-Words-representation-구현-절차-1.2.1.1\">Bag-of-Words representation 구현 절차</a></span></li><li><span><a href=\"#lexicon-만들기-:-list\" data-toc-modified-id=\"lexicon-만들기-:-list-1.2.1.2\">lexicon 만들기 : list</a></span></li><li><span><a href=\"#lexicon-만들기(속도-개선)-:-list-=&gt;-set\" data-toc-modified-id=\"lexicon-만들기(속도-개선)-:-list-=>-set-1.2.1.3\">lexicon 만들기(속도 개선) : list =&gt; set</a></span></li><li><span><a href=\"#BOW-만들기-:-list\" data-toc-modified-id=\"BOW-만들기-:-list-1.2.1.4\">BOW 만들기 : list</a></span></li><li><span><a href=\"#BOW-속도-개선(1)-:-list-=&gt;-dict\" data-toc-modified-id=\"BOW-속도-개선(1)-:-list-=>-dict-1.2.1.5\">BOW 속도 개선(1) : list =&gt; dict</a></span></li><li><span><a href=\"#BOW-속도-개선(2)-:-dict-=&gt;-defaultdict,-lexicon-사전-비교-안하기\" data-toc-modified-id=\"BOW-속도-개선(2)-:-dict-=>-defaultdict,-lexicon-사전-비교-안하기-1.2.1.6\">BOW 속도 개선(2) : dict =&gt; defaultdict, lexicon 사전 비교 안하기</a></span></li></ul></li><li><span><a href=\"#DTM-=&gt;-TDM-변환\" data-toc-modified-id=\"DTM-=>-TDM-변환-1.2.2\">DTM =&gt; TDM 변환</a></span></li><li><span><a href=\"#서비스-구현-시-추가-고려사항-(Postings-list)\" data-toc-modified-id=\"서비스-구현-시-추가-고려사항-(Postings-list)-1.2.3\">서비스 구현 시 추가 고려사항 (Postings list)</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정보검색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 버지니아공대 정보검색 강좌 : http://www.cs.virginia.edu/~hw5x/Course/IR2015/_site/lectures/\n",
    "\n",
    "- google 검색엔진 : Text Retrieval Conference(TREC, NLP 분야의 가장 공신력 있는 학회)에 논문 발표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to perform information retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 색인을 위해 자연어 처리 기술을 사용함\n",
    "- 검색을 structured data에서는 search라고 표현하지만, unstructured data에서는 retrieval이라고 표현함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![how_retrieval](./images/information_retrieval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic search engine architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstraction of search engine architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![abstraction](./images/Abstraction_of_search_engine_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One sentence about IR\n",
    "\n",
    "- “rank documents by their relevance to the information need”\n",
    "- 정보 니즈와의 관련성에 따라 문서의 순위를 매기는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you should know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Basic workflow and components in a IR system** : crawler, analyzer, indexer, Query parser, Ranking model, <br>\n",
    "    Result display, Retrieval evaluation, Relevance feedback\n",
    "- **Core concepts in IR** : Information need, Query, Document, Relevance, \n",
    "- Browsing v.s. **querying**\n",
    "- **Pull** v.s. push of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Crawling and Basic Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does it work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In pseudo code\n",
    "\n",
    "~~~\n",
    "Def Crawler(entry_point) {\n",
    "    URL_list = [entry_point]\n",
    "    while (len(URL_list)>0) {\n",
    "            URL = URL_list.pop();\n",
    "            if (isVisited(URL) or !isLegal(URL) or !checkRobotsTxt(URL))\n",
    "                  continue;\t\t\t\t\n",
    "            HTML = URL.open();\t\n",
    "            for (anchor in HTML.listOfAnchors()) {\n",
    "                   URL_list.append(anchor);\n",
    "             }\n",
    "             setVisited(URL);\n",
    "             insertToIndex(HTML);\n",
    "    }\n",
    "}\n",
    "~~~\n",
    "\n",
    "![pseudo](./images/pseudo_code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you should know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basic techniques for crawling : Visiting strategy(Breadth first, Depthfirst vs. Focused crawling), Avoid duplicate visit,<br>\n",
    "   Politeness policy, Re-visit policy, Analyze crawled web pages, HTML parsing(html.parser, jsoup/json)\n",
    "- Zipf’s law\n",
    "- Procedures for automatic text indexing : Tokenization, Normalization, Stemming, Stopwords\n",
    "- Bag-of-Words document representation\n",
    "\n",
    "![BOW](./images/BOW.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 색인기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full text indexing : Bag-of-Words representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assumption: word is independent from each other\n",
    "- Pros: simple\n",
    "- Cons: grammar and order are missing\n",
    "- The most frequently used document representation : Image, speech, gene sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-Words representation 구현 절차\n",
    "\n",
    "1. 크롤링\n",
    "1. collection => document 집합\n",
    "1. Word split => Tokenize, Preprocessing\n",
    "1. Lexicon Dictionary (|V|) => 전체 문서의 token 리스트\n",
    "1. 문서 표현 (by BOW) => Lexicon Dictionary의 token이 해당 문서에 있으면 1, 없으면 0으로 표현된 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lexicon 만들기 : list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kobill\n",
    "\n",
    "def getLexicon():    # list 사용\n",
    "    lexicon = list()\n",
    "\n",
    "    for docName in kobill.fileids():\n",
    "        document = kobill.open(docName).read()\n",
    "\n",
    "        for token in document.split():\n",
    "            if token not in lexicon:\n",
    "                lexicon.append(token)\n",
    "                \n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit getLexicon()   # 속도가 느림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lexicon 만들기(속도 개선) : list => set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kobill\n",
    "\n",
    "def getLexicon():    # set 사용\n",
    "    lexicon = set()\n",
    "\n",
    "    for docName in kobill.fileids():\n",
    "        document = kobill.open(docName).read()\n",
    "\n",
    "        for token in document.split():\n",
    "                lexicon.add(token)\n",
    "                \n",
    "    return list(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.58 ms ± 54.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit getLexicon()   # set을 사용해서 if문을 없앴기 때문에 속도가 개선됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2638"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = getLexicon()\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW 만들기 : list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어사전: [0:단어1, 1:단어2, 2:단어3, ...]\n",
    "# 문서:     0:  [0:0 or 1, ...] => 문서에 있으면 1, 없으면 0으로 표현\n",
    "#              1: \n",
    "# 문서목록 : [0:문서1, 1:문서2, ...]\n",
    "\n",
    "# 문서는 모두 서로 다르다고 가정 : 같은 문서가 있는 경우 set을 사용할 수 없음\n",
    "\n",
    "def getDocRepr(lexicon):\n",
    "    docList = list()    # 문서목록\n",
    "    docRepr = list()   # 문서표현 of BOW의 집합 => 문서 갯수 만큼\n",
    "    # 0: BOW\n",
    "    # 1: BOW\n",
    "    # 2: BOW\n",
    "    # ...\n",
    "\n",
    "    for docName in kobill.fileids():\n",
    "        document = kobill.open(docName).read()\n",
    "        \n",
    "        docList.append(docName)\n",
    "        docVector = list(0 for _ in range(len(lexicon)))   # 문서 1개에 대한 문서표현(BOW) = [0] * 단어의 갯수\n",
    "\n",
    "        for token in document.split():\n",
    "            if token in lexicon:\n",
    "                docVector[lexicon.index(token)] = 1   # 문서 사전에 있으면, BOW 표현을 1로 변경\n",
    "\n",
    "        docRepr.append(docVector)\n",
    "        \n",
    "    return docList, docRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, '2011년에', 2638)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docList, docRepr = getDocRepr(lexicon)\n",
    "len(docList), len(docRepr), lexicon[2], len(docRepr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docRepr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 ms ± 3.27 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit getDocRepr(lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW 속도 개선(1) : list => dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문제점 : 전체 리스트에서 0인 부분이 너무 많고, 문서가 많아질수록 더 심해짐\n",
    "- 개선방안 : BOW를 list가 아닌 dictionary 형태로 변경(token이 있는 부분만 저장) <br>\n",
    "   ==> lexicon dicitionary에서 비교하지 않고, token을 직접 key로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW dictrionary 표현\n",
    "\n",
    "def getDocReprByDict(lexicon):\n",
    "    # docList = list()    # 문서목록 => 필요 없음\n",
    "    docRepr = dict()   # 문서표현 of BOW의 Dictionary\n",
    "    # key => 문서\n",
    "    # Value => BOW => list x, dict\n",
    "\n",
    "    for docName in kobill.fileids():\n",
    "        document = kobill.open(docName).read()\n",
    "        \n",
    "        docRepr[docName] = dict()\n",
    "\n",
    "        for token in document.split():\n",
    "            if token in lexicon:\n",
    "                docRepr[docName][lexicon.index(token)] = 1   # 문서 사전에 있으면, BOW 표현을 1로 변경\n",
    "\n",
    "        \n",
    "    return docRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "docRepr = getDocReprByDict(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, '1809896.txt')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docRepr), list(docRepr.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, '정하는')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docRepr['1809896.txt'][1328], lexicon[1328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336 ms ± 41.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit getDocReprByDict(lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW 속도 개선(2) : dict => defaultdict, lexicon 사전 비교 안하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaultdict로 변경\n",
    "from collections import defaultdict\n",
    "\n",
    "def getDocReprByDefaultDict(lexicon):\n",
    "    docRepr = defaultdict(lambda: defaultdict(int))   # 문서표현 of BOW의 Dictionary\n",
    "\n",
    "    for docName in kobill.fileids():\n",
    "        document = kobill.open(docName).read()\n",
    "        \n",
    "        for token in document.split():\n",
    "            docRepr[docName][token] = 1   # 문서 사전을 비교하지 않고, token을 key로 바로 사용 => BOW 표현을 1로 변경\n",
    "            # lexicon 사전을 만들 때 이미 해당 문서의 모든 token을 포함시겼기 때문에 비교하지 않고 token을 바로 key로 사용함\n",
    "        \n",
    "    return docRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "docRepr = getDocReprByDefaultDict(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, '1809896.txt')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docRepr), list(docRepr.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '건의에')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docRepr['1809896.txt'][100], lexicon[100]    # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.49 ms ± 14 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit getDocReprByDefaultDict(lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTM => TDM 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검색 => Input(키워드들의 집합 = Query) <br>\n",
    "키워드들은 단어로 구성, 단어를 추출\n",
    "\n",
    "Q = \\[\"국회\", \"의원\"]  이라면,\n",
    "\n",
    "|Q| = q, |D| = d, |V| = v 라면,<br>\n",
    "q**d, **v   ==> 너무 과다한 계산 (실행 불가)\n",
    "\n",
    "for 단어 in Q:<br>\n",
    "    for 전체 문서를 대상:<br>\n",
    "            for 문서 내 단어 :<br>\n",
    "                if 단어 == 사전:<br>\n",
    "                    이때의 해당 문서가 검색 후보\n",
    "\n",
    "---------\n",
    "이를 개선하기 위해,<br>\n",
    "InvertedDocument (역문헌 구조)를 사용<br>\n",
    "key: 단어 in 사전,<br>\n",
    "val: 어느 문서에서 나왔는지, 몇 번(, 어느 위치 등)\n",
    "\n",
    "for 단어 in Q:\n",
    "    # for 전체 문서를 대상:  # 전체 문서를 대상으로 찾을 필요 없음\n",
    "    #        for 문서 내 단어 :\n",
    "    #            if 단어 == 사전:\n",
    "    단어 in InvertedDocument.keys():\n",
    "                    이때의 해당 문서가 검색 후보\n",
    "\n",
    "----------\n",
    "            DTM(Document-Term Matrix)\n",
    "            W1, W1, W3, ... Wn\n",
    "Doc1    0,   1,  0,  1, 0, 0, 0, 0 <br>\n",
    "Doc2<br>\n",
    "...<br>\n",
    "Doc10<br>\n",
    "\n",
    "DTM => TDM으로 변경 (리스트 x, 딕셔너리 o => 공간을 줄일려고)\n",
    "\n",
    "            TDM(Term-Document Matrix)\n",
    "            D1, D1, D3, ... D10\n",
    "W1    0,   1,  0,  1, 0, 0, 0, 0<br>\n",
    "W2<br>\n",
    "...<br>\n",
    "Wn<br>\n",
    "\n",
    "----------\n",
    "Query의 경우에도:\n",
    "            W1, W1, W3, ... Wn <br>\n",
    "Q1    0,   1,  0,  1, 0, 0, 0, 0 <br>\n",
    "Q2<br>\n",
    "Q3<br>\n",
    "\n",
    "문자들의 검색 결과를 one-hot 벡터로 합해서 표현하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTM을 TDM으로 변경\n",
    "def convertInvertedDocument(DTM):\n",
    "    TDM = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for fileName, termList in DTM.items():   # DTM[fileName][term]\n",
    "        for term, freq in termList.items():\n",
    "            TDM[term][fileName] = freq\n",
    "            \n",
    "    return TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDM = convertInvertedDocument(docRepr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(int, {'1809897.txt': 1, '1809898.txt': 1}),\n",
       " defaultdict(int, {'1809896.txt': 1}))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean 검색\n",
    "TDM[\"국회\"], TDM[\"의원\"]  # Boolean Model 이라고 함 (&, |, not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'1809897.txt': 1, '1809898.txt': 1})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDM[\"국회\"] or TDM[\"의원\"]  # Boolean Model 이라고 함 (&, |, not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서비스 구현 시 추가 고려사항 (Postings list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 서비스로 구현하기 위해서는 POSTING 파일을 따로 만들어서 in-memory에 올려서 처리해야 함 (hash 파일 구조 DB)<br>\n",
    "   (python 코드는 구현은 쉽지만, 서비스 속도에 문제가 있음)\n",
    "\n",
    "\n",
    "- 단어 -> 포스트파일 위치\n",
    "\n",
    "    POSTING-구조체 (파일DB) <br>\n",
    "    위치:\\[어느문서:면번, 다음위치:...\\]\\[어느문서:면번, 다음위치:...\\]위치:\\[어느문서:면번, 다음위치:...\\]...\n",
    "\n",
    "\n",
    "- (inverted document) Postings list (Lucene)\n",
    "\n",
    "![posting](./images/posting_list.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
