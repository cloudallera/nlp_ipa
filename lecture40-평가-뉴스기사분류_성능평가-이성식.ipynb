{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#최종평가-:-category-classification-evaluation\" data-toc-modified-id=\"최종평가-:-category-classification-evaluation-1\">최종평가 : category classification evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#과제-내용\" data-toc-modified-id=\"과제-내용-1.1\">과제 내용</a></span><ul class=\"toc-item\"><li><span><a href=\"#[classification]-:-프로젝트3(kNN),-프로젝트4(Naive-Bayes)\" data-toc-modified-id=\"[classification]-:-프로젝트3(kNN),-프로젝트4(Naive-Bayes)-1.1.1\">[classification] : 프로젝트3(kNN), 프로젝트4(Naive Bayes)</a></span></li><li><span><a href=\"#[Evlauation]-:-F-Measure\" data-toc-modified-id=\"[Evlauation]-:-F-Measure-1.1.2\">[Evlauation] : F-Measure</a></span></li></ul></li><li><span><a href=\"#문제-풀이\" data-toc-modified-id=\"문제-풀이-1.2\">문제 풀이</a></span><ul class=\"toc-item\"><li><span><a href=\"#package-import\" data-toc-modified-id=\"package-import-1.2.1\">package import</a></span></li><li><span><a href=\"#학습\" data-toc-modified-id=\"학습-1.2.2\">학습</a></span><ul class=\"toc-item\"><li><span><a href=\"#수집한-문서목록-가져오기\" data-toc-modified-id=\"수집한-문서목록-가져오기-1.2.2.1\">수집한 문서목록 가져오기</a></span></li><li><span><a href=\"#각-문서에서-색인어-추출-전처리\" data-toc-modified-id=\"각-문서에서-색인어-추출-전처리-1.2.2.2\">각 문서에서 색인어 추출 전처리</a></span></li><li><span><a href=\"#train-set,-test-set-분리\" data-toc-modified-id=\"train-set,-test-set-분리-1.2.2.3\">train set, test set 분리</a></span></li><li><span><a href=\"#Inverted-Index-:-DTM\" data-toc-modified-id=\"Inverted-Index-:-DTM-1.2.2.4\">Inverted Index : DTM</a></span></li><li><span><a href=\"#DTM\" data-toc-modified-id=\"DTM-1.2.2.5\">DTM</a></span></li><li><span><a href=\"#TDM\" data-toc-modified-id=\"TDM-1.2.2.6\">TDM</a></span></li><li><span><a href=\"#TWM\" data-toc-modified-id=\"TWM-1.2.2.7\">TWM</a></span></li><li><span><a href=\"#Evaluate-IDF\" data-toc-modified-id=\"Evaluate-IDF-1.2.2.8\">Evaluate IDF</a></span></li></ul></li><li><span><a href=\"#Validation\" data-toc-modified-id=\"Validation-1.2.3\">Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Bayes-Validation\" data-toc-modified-id=\"Naive-Bayes-Validation-1.2.3.1\">Naive Bayes Validation</a></span></li></ul></li><li><span><a href=\"#test-data-성능평가\" data-toc-modified-id=\"test-data-성능평가-1.2.4\">test data 성능평가</a></span><ul class=\"toc-item\"><li><span><a href=\"#test-data-읽어오기\" data-toc-modified-id=\"test-data-읽어오기-1.2.4.1\">test data 읽어오기</a></span></li><li><span><a href=\"#Test-Data-Prediction\" data-toc-modified-id=\"Test-Data-Prediction-1.2.4.2\">Test Data Prediction</a></span></li><li><span><a href=\"#성능-평가\" data-toc-modified-id=\"성능-평가-1.2.4.3\">성능 평가</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종평가 : category classification evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [classification] : 프로젝트3(kNN), 프로젝트4(Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 뉴스 기사 분류 (kNN)\n",
    "2. 뉴스 기사 분류 (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Evlauation] : F-Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. kNN : k값을 1, 3, 5, 7, 9로 변경하면서 Precision, Recall, F-Measure 평가\n",
    "4. Naive Bayes : 뉴스 기사를 traing set과 validation set으로 분리하여 Precision, Recall, F-Measure 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 풀이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.naver import NewsScraping\n",
    "\n",
    "from functions.info_retrieval import max_tf, raw_idf\n",
    "from functions.info_retrieval import smoothig_idf\n",
    "from functions.info_retrieval import clean_collection\n",
    "from functions.info_retrieval import extend_lexicon\n",
    "from functions.info_retrieval import inverted_index_with_tf\n",
    "from functions.info_retrieval import get_tdm_from_dtm\n",
    "from functions.info_retrieval import tdm2twm\n",
    "from functions.info_retrieval import evaluate_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = {\n",
    "    '정치': '00',\n",
    "    '경제': '01',\n",
    "    '사회': '02',\n",
    "    '생활문화': '03',\n",
    "    '세계': '04',\n",
    "    'IT과학': '05'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_category = {\n",
    "    '00': '정치',\n",
    "    '01': '경제',\n",
    "    '02': '사회',\n",
    "    '03': '생활문화',\n",
    "    '04': '세계',\n",
    "    '05': 'IT과학'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수집한 문서목록 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = NewsScraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = news.get_filenames(all_folder=True)\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []   # tuple(filename, content)들의 list\n",
    "\n",
    "for filename in filenames:\n",
    "    collection.append((filename.split(\"/\")[-1], news.get_content(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#collection[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 문서에서 색인어 추출 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불용어 제거\n",
    "- 어절 -> 형태소 + 명사 + 바이그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_collection = clean_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cleaned_collection[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 개 documents 중 30 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 60 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 90 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 120 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 150 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 180 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 210 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 240 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 270 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 300 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 330 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 360 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 390 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 420 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 450 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 480 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 510 개 documents의 lexicon 추출 완료\n",
      "540 개 documents 중 540 개 documents의 lexicon 추출 완료\n",
      "540 개 documents의 lexicon 추출 완료\n"
     ]
    }
   ],
   "source": [
    "extended_collection = []\n",
    "corpus_count = len(cleaned_collection)\n",
    "\n",
    "for idx, (filename, corpus) in enumerate(cleaned_collection):\n",
    "    extended_lexicon = extend_lexicon(corpus)\n",
    "    extended_collection.append((filename, extended_lexicon))\n",
    "    if (idx + 1) % 30 == 0:\n",
    "        print(corpus_count, \"개 documents 중\", idx + 1, \"개 documents의 lexicon 추출 완료\")\n",
    "\n",
    "print(idx + 1, \"개 documents의 lexicon 추출 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extended_collection[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train set, test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = extended_collection\n",
    "target = [filename.split(\"-\")[0] for filename, content in extended_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('00-01-0010682284.txt',\n",
       "  array(['앵커', '불법', '병역', ..., '뉴스', '케이', '이야'], dtype='<U32')),\n",
       " '00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[0], target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_target, val_target = train_test_split(data_set, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 432, 108, 108)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_target), len(val_data), len(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('00-05-0010726642.txt',\n",
       "  array(['2013년', '3월', '13일', ..., '뉴스', '스영', '영상'], dtype='<U32')),\n",
       " '00',\n",
       " ('04-07-0002895933.txt',\n",
       "  array(['나루히토', '일왕이', '즉위하는', ..., '재배', '배포', '금지'], dtype='<U32')),\n",
       " '04')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1], train_target[1], val_data[-1], val_target[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_category = dict()\n",
    "for (filename, content), target in zip(train_data, train_target):\n",
    "    train_data_category[filename] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverted Index : DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80464, 306613, 432, 432)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_lexicon, global_posting, global_document, dtm = inverted_index_with_tf(train_data)\n",
    "len(global_lexicon), len(global_posting), len(global_document), len(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_posting[3000:3020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#global_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm    # DTM은 Inverted Index(색인) 시 함께 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm = get_tdm_from_dtm(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "twm, dtw = tdm2twm(tdm, global_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#twm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lexicon_idf, global_document_weight = evaluate_idf(global_lexicon, global_posting, global_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_lexicon_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_document_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes 분류 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습**\n",
    "\n",
    "1. 학습 데이터 카테고리별 문서 수 계산 및 사전 확율 계산 = 카테고리 문서 수 / 전체 문서 수\n",
    "2. 학습 데이터 카테고리별 token 추출(전처리, 토큰 확장) => train_data에 추출되어 있음\n",
    "3. 학습 데이터 카테고리별 token의 조건부 확률 계산\n",
    "\n",
    "**분류**\n",
    "\n",
    "4. Validation 데이터별 token 추출(전처리, 토큰 확장) => val_data에 추출되어 있음\n",
    "5. Validation 데이터별 카테고리별 조건부 확률 계산 (학습으로 산출된 token의 조건부 확률 합)\n",
    "6. 조건부 확률이 가장 높은 카테고리 선택 (prediction)\n",
    "\n",
    "**평가(validation)**\n",
    "\n",
    "7. Validation 데이터 labels와 prediction 값 비교\n",
    "\n",
    "**평가(test)**\n",
    "\n",
    "8. test data에 대해 분류, 평가(4~7번 항목)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 사전 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('00', 74), ('05', 72), ('03', 76), ('01', 62), ('04', 74), ('02', 74)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_freq = defaultdict()\n",
    "\n",
    "for target in train_target:\n",
    "    if target not in train_freq.keys():\n",
    "        train_freq[target] = 1\n",
    "    else:\n",
    "        train_freq[target] += 1\n",
    "\n",
    "train_freq.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 0.1712962962962963,\n",
       " '05': 0.16666666666666666,\n",
       " '03': 0.17592592592592593,\n",
       " '01': 0.14351851851851852,\n",
       " '04': 0.1712962962962963,\n",
       " '02': 0.1712962962962963}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_length = len(train_target)\n",
    "prior = dict()\n",
    "\n",
    "for cat, cat_freq in train_freq.items():\n",
    "    prior[cat] = cat_freq / train_data_length\n",
    "\n",
    "prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 카테고리별 단어 빈도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "for data, target in zip(train_data, train_target):\n",
    "    for token in data[1]:\n",
    "        tokens[target][token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "tokens_count = dict()\n",
    "\n",
    "for cat, term_freq in tokens.items():\n",
    "    vocabulary.update(term_freq.keys())\n",
    "    tokens_count[cat] = sum(term_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80464"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 138246,\n",
       " '05': 119041,\n",
       " '03': 124455,\n",
       " '01': 113530,\n",
       " '04': 116018,\n",
       " '02': 113946}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 카테고리별 token의 조건부 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "condprob = defaultdict(lambda : defaultdict(float))\n",
    "\n",
    "B = len(vocabulary)\n",
    "\n",
    "for token in vocabulary:\n",
    "    for cat in inverse_category.keys():\n",
    "        condprob[cat][token] = log((tokens[cat][token] + 1) / (tokens_count[cat] + B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 108\n",
      "('04-10-0000026378.txt', array(['주간동아', '트뤼도', '캐나다', ..., '거진', '진동', '동아'], dtype='<U32'))\n"
     ]
    }
   ],
   "source": [
    "print(len(val_data), len(val_target))\n",
    "print(val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = []\n",
    "\n",
    "for vd in val_data:\n",
    "    val_score = dict()\n",
    "\n",
    "    for cat in inverse_category.keys():\n",
    "        val_score[cat] = log(prior[cat])\n",
    "\n",
    "        for token in vd[1]:\n",
    "            val_score[cat] += condprob[cat][token]\n",
    "\n",
    "    val_pred.append(max(val_score, key=val_score.get))    # prediction (가장 높은 조건부 확률의 카테고리 선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '04', '02', '04', '01', '05', '00', '04', '02', '00', '05', '04', '00', '04', '01', '01', '04', '04', '05', '01', '00', '05', '04', '05', '00', '00', '05', '01', '05', '01', '05', '00', '04', '04', '04', '01', '01', '01', '02', '02', '00', '01', '01', '01', '01', '00', '03', '05', '03', '05', '03', '01', '04', '04', '02', '04', '01', '01', '02', '00', '03', '02', '05', '01', '00', '04', '04', '03', '05', '05', '02', '03', '02', '00', '01', '00', '05', '02', '02', '05', '03', '02', '01', '02', '01', '05', '02', '05', '03', '02', '03', '03', '01', '01', '01', '00', '01', '04', '02', '01', '00', '03', '01', '02', '01', '03', '04']\n"
     ]
    }
   ],
   "source": [
    "print(val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  1,  0,  2,  0],\n",
       "       [ 1, 21,  1,  1,  0,  4],\n",
       "       [ 0,  2, 14,  0,  0,  0],\n",
       "       [ 0,  1,  1, 11,  1,  0],\n",
       "       [ 1,  1,  0,  0, 14,  0],\n",
       "       [ 1,  3,  0,  0,  1, 13]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = confusion_matrix(val_target, val_pred)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          00       0.81      0.81      0.81        16\n",
      "          01       0.75      0.75      0.75        28\n",
      "          02       0.82      0.88      0.85        16\n",
      "          03       0.92      0.79      0.85        14\n",
      "          04       0.78      0.88      0.82        16\n",
      "          05       0.76      0.72      0.74        18\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       108\n",
      "   macro avg       0.81      0.80      0.80       108\n",
      "weighted avg       0.80      0.80      0.80       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_target, val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data 성능평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['경제-20190408160048011.txt',\n",
       " '생활문화-20190407n15403.txt',\n",
       " 'IT과학-20190408n31939.txt',\n",
       " '생활문화-20190408113300382.txt',\n",
       " '경제-20190408n25064.txt',\n",
       " '세계-20190408150242297.txt',\n",
       " 'IT과학-20190408163613503.txt',\n",
       " '세계-20190408n27328.txt',\n",
       " '정치-20190408161154495.txt',\n",
       " '사회-20190408n29162.txt',\n",
       " '사회-20190408162921246.txt',\n",
       " '정치-20190408n27206.txt']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"news_classification_testing_data\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '03', '05', '03', '01', '04', '05', '04', '00', '02', '02', '00']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target = [category[file.split(\"-\")[0]] for file in files]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collection = []   # 2차원 배열 : [[filename, content]]\n",
    "\n",
    "for filename in files:\n",
    "    with open(os.path.join(\"news_classification_testing_data\", filename), \"r\") as f:\n",
    "        test_collection.append([filename, f.read()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collection_cleaned = clean_collection(test_collection)\n",
    "# test_collection_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "corpus_count = len(test_collection_cleaned)\n",
    "\n",
    "for idx, (filename, corpus) in enumerate(test_collection_cleaned):\n",
    "    extended_lexicon = extend_lexicon(corpus)\n",
    "    test_data.append([filename, extended_lexicon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['경제-20190408160048011.txt',\n",
       " array(['코스피가', '8일', '외국인', ..., '마감', '감했', '했다'], dtype='<U32')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12\n",
      "['경제-20190408160048011.txt', array(['코스피가', '8일', '외국인', ..., '마감', '감했', '했다'], dtype='<U32')]\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data), len(test_target))\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "\n",
    "for td in test_data:\n",
    "    test_score = dict()\n",
    "\n",
    "    for cat in inverse_category.keys():\n",
    "        test_score[cat] = log(prior[cat])\n",
    "\n",
    "        for token in td[1]:\n",
    "            test_score[cat] += condprob[cat][token]\n",
    "\n",
    "    test_pred.append(max(test_score, key=test_score.get))    # prediction (가장 높은 조건부 확률의 카테고리 선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '05', '05', '03', '01', '04', '05', '04', '00', '02', '01', '00']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 0, 2]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = confusion_matrix(test_target, test_pred)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          00       0.81      0.81      0.81        16\n",
      "          01       0.75      0.75      0.75        28\n",
      "          02       0.82      0.88      0.85        16\n",
      "          03       0.92      0.79      0.85        14\n",
      "          04       0.78      0.88      0.82        16\n",
      "          05       0.76      0.72      0.74        18\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       108\n",
      "   macro avg       0.81      0.80      0.80       108\n",
      "weighted avg       0.80      0.80      0.80       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_target, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
